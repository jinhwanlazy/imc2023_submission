{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cdbf433-5b27-4071-9f56-d0338bfeeb64",
   "metadata": {},
   "source": [
    "# Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86526175-8f37-4d95-8deb-e2aa098dccdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "-- Found installed version of Eigen: /usr/lib/cmake/eigen3\n",
      "-- Found required Ceres dependency: Eigen version 3.3.7 in /usr/include/eigen3\n",
      "-- Found required Ceres dependency: glog\n",
      "-- Found installed version of gflags: /usr/lib/x86_64-linux-gnu/cmake/gflags\n",
      "-- Detected gflags version: 2.2.2\n",
      "-- Found required Ceres dependency: gflags\n",
      "-- Found Ceres version: 1.14.0 installed in: /usr with components: [EigenSparse, SparseLinearAlgebraLibrary, LAPACK, SuiteSparse, CXSparse, SchurSpecializations, OpenMP, Multithreading]\n",
      "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.71.0/BoostConfig.cmake (found version \"1.71.0\") found components: program_options filesystem graph system unit_test_framework \n",
      "-- Found Eigen\n",
      "--   Includes : /usr/include/eigen3\n",
      "-- Found FreeImage\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/libfreeimage.so\n",
      "-- Found FLANN\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/libflann.so\n",
      "-- Found LZ4\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/liblz4.so\n",
      "-- Found Glog\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/libglog.so\n",
      "-- Found SQLite3\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/libsqlite3.so\n",
      "-- Found Glew\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : /usr/lib/x86_64-linux-gnu/libGLEW.so\n",
      "-- Using header-only CGAL\n",
      "-- Targetting Ninja\n",
      "-- Using /usr/bin/c++ compiler.\n",
      "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.71.0/BoostConfig.cmake (found suitable version \"1.71.0\", minimum required is \"1.48\")  \n",
      "-- Boost include dirs: /usr/include\n",
      "-- Boost libraries:    \n",
      "-- Using gcc version 4 or later. Adding -frounding-math\n",
      "-- Found Qt\n",
      "--   Module : /usr/lib/x86_64-linux-gnu/cmake/Qt5Core\n",
      "--   Module : /usr/lib/x86_64-linux-gnu/cmake/Qt5OpenGL\n",
      "--   Module : /usr/lib/x86_64-linux-gnu/cmake/Qt5Widgets\n",
      "-- Found CGAL\n",
      "--   Includes : /usr/include\n",
      "--   Libraries : CGAL\n",
      "-- Build type not specified, using Release\n",
      "-- Enabling SIMD support\n",
      "-- Enabling OpenMP support\n",
      "-- Disabling interprocedural optimization\n",
      "-- Enabling CUDA support (version: 11.3.109, archs: native)\n",
      "-- Enabling GUI support\n",
      "-- Enabling OpenGL support\n",
      "-- Disabling ccache support\n",
      "-- Disabling profiling support\n",
      "-- Enabling CGAL support\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /kaggle/working/colmap/build\n",
      "[1/127] Building CUDA object src/CMakeFiles/colmap_cuda.dir/mvs/patch_match_cuda.cu.o\n",
      "[2/127] Linking CXX static library src/libcolmap_cuda.a\n",
      "[3/127] Automatic RCC for ui/resources.qrc\n",
      "[4/127] Building CXX object src/CMakeFiles/colmap.dir/base/camera_database.cc.o\n",
      "[5/127] Building CXX object src/CMakeFiles/colmap.dir/base/point2d.cc.o\n",
      "[6/127] Building CXX object src/CMakeFiles/colmap.dir/base/point3d.cc.o\n",
      "[7/127] Building CXX object src/CMakeFiles/colmap.dir/base/track.cc.o\n",
      "[8/127] Building CXX object src/CMakeFiles/colmap.dir/base/visibility_pyramid.cc.o\n",
      "[9/127] Building CXX object src/CMakeFiles/colmap.dir/base/line.cc.o\n",
      "[10/127] Building CXX object src/CMakeFiles/colmap.dir/base/gps.cc.o\n",
      "[11/127] Building CXX object src/CMakeFiles/colmap.dir/base/warp.cc.o\n",
      "[12/127] Building CXX object src/CMakeFiles/colmap.dir/base/image.cc.o\n",
      "[13/127] Building CXX object src/CMakeFiles/colmap.dir/base/correspondence_graph.cc.o\n",
      "[14/127] Building CXX object src/CMakeFiles/colmap.dir/base/camera_models.cc.o\n",
      "[15/127] Building CXX object src/CMakeFiles/colmap.dir/base/database_cache.cc.o\n",
      "[16/127] Building CXX object src/CMakeFiles/colmap.dir/base/camera.cc.o\n",
      "[17/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/utils.cc.o\n",
      "[18/127] Building CXX object src/CMakeFiles/colmap.dir/base/graph_cut.cc.o\n",
      "[19/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/triangulation.cc.o\n",
      "[20/127] Building CXX object src/CMakeFiles/colmap.dir/base/camera_rig.cc.o\n",
      "[21/127] Building CXX object src/CMakeFiles/colmap.dir/base/reconstruction_manager.cc.o\n",
      "[22/127] Building CXX object src/CMakeFiles/colmap.dir/base/homography_matrix.cc.o\n",
      "[23/127] Building CXX object src/CMakeFiles/colmap.dir/controllers/incremental_mapper.cc.o\n",
      "[24/127] Building CXX object src/CMakeFiles/colmap.dir/base/image_reader.cc.o\n",
      "[25/127] Building CXX object src/CMakeFiles/colmap.dir/controllers/bundle_adjustment.cc.o\n",
      "[26/127] Building CXX object src/CMakeFiles/colmap.dir/feature/types.cc.o\n",
      "[27/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/generalized_absolute_pose.cc.o\n",
      "[28/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/depth_map.cc.o\n",
      "[29/127] Building CXX object src/CMakeFiles/colmap.dir/base/database.cc.o\n",
      "[30/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/consistency_graph.cc.o\n",
      "[31/127] Building CXX object src/CMakeFiles/colmap.dir/optim/combination_sampler.cc.o\n",
      "[32/127] Building CXX object src/CMakeFiles/colmap.dir/base/scene_clustering.cc.o\n",
      "[33/127] Building CXX object src/CMakeFiles/colmap.dir/feature/utils.cc.o\n",
      "[34/127] Building CXX object src/CMakeFiles/colmap.dir/controllers/hierarchical_mapper.cc.o\n",
      "[35/127] Building CXX object src/CMakeFiles/colmap.dir/optim/sprt.cc.o\n",
      "[36/127] Building CXX object src/CMakeFiles/colmap.dir/optim/support_measurement.cc.o\n",
      "[37/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/two_view_geometry.cc.o\n",
      "[38/127] Building CXX object src/CMakeFiles/colmap.dir/base/triangulation.cc.o\n",
      "[39/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/normal_map.cc.o\n",
      "[40/127] Building CXX object src/CMakeFiles/colmap.dir/optim/random_sampler.cc.o\n",
      "[41/127] Building CXX object src/CMakeFiles/colmap.dir/base/essential_matrix.cc.o\n",
      "[42/127] Building CXX object src/CMakeFiles/colmap.dir/base/pose.cc.o\n",
      "[43/127] Building CXX object src/CMakeFiles/colmap.dir/base/polynomial.cc.o\n",
      "[44/127] Building CXX object src/CMakeFiles/colmap.dir/util/logging.cc.o\n",
      "[45/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/image.cc.o\n",
      "[46/127] Building CXX object src/CMakeFiles/colmap.dir/util/math.cc.o\n",
      "[47/127] Building CXX object src/CMakeFiles/colmap.dir/optim/progressive_sampler.cc.o\n",
      "[48/127] Building CXX object src/CMakeFiles/colmap.dir/base/similarity_transform.cc.o\n",
      "[49/127] Building CXX object src/CMakeFiles/colmap.dir/retrieval/geometry.cc.o\n",
      "[50/127] Building CXX object src/CMakeFiles/colmap.dir/util/random.cc.o\n",
      "[51/127] Building CXX object src/CMakeFiles/colmap.dir/util/opengl_utils.cc.o\n",
      "[52/127] Building CXX object src/CMakeFiles/colmap.dir/util/timer.cc.o\n",
      "[53/127] Building CXX object src/CMakeFiles/colmap.dir/controllers/automatic_reconstruction.cc.o\n",
      "[54/127] Building CXX object src/CMakeFiles/colmap.dir/feature/extraction.cc.o\n",
      "[55/127] Building CXX object src/CMakeFiles/colmap.dir/util/threading.cc.o\n",
      "[56/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/generalized_absolute_pose_coeffs.cc.o\n",
      "[57/127] Building CXX object src/CMakeFiles/colmap.dir/util/version.cc.o\n",
      "[58/127] Building CXX object src/CMakeFiles/colmap.dir/util/string.cc.o\n",
      "[59/127] Building CXX object src/CMakeFiles/colmap.dir/util/misc.cc.o\n",
      "[60/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/affine_transform.cc.o\n",
      "[61/127] Building CXX object src/CMakeFiles/colmap.dir/base/reconstruction.cc.o\n",
      "[62/127] Building CXX object src/CMakeFiles/colmap.dir/base/undistortion.cc.o\n",
      "[63/127] Building CXX object src/CMakeFiles/colmap.dir/retrieval/vote_and_verify.cc.o\n",
      "[64/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/workspace.cc.o\n",
      "[65/127] Building CXX object src/CMakeFiles/colmap.dir/util/ply.cc.o\n",
      "[66/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/model.cc.o\n",
      "[67/127] Building CXX object src/CMakeFiles/colmap.dir/optim/least_absolute_deviations.cc.o\n",
      "[68/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/fusion.cc.o\n",
      "[69/127] Building CXX object src/CMakeFiles/colmap.dir/sfm/incremental_triangulator.cc.o\n",
      "[70/127] Building CXX object src/CMakeFiles/colmap.dir/base/projection.cc.o\n",
      "[71/127] Building CXX object src/CMakeFiles/colmap.dir/util/camera_specs.cc.o\n",
      "[72/127] Building CXX object src/CMakeFiles/colmap.dir/ui/colormaps.cc.o\n",
      "[73/127] Building CXX object src/CMakeFiles/colmap.dir/util/bitmap.cc.o\n",
      "[74/127] Building CXX object src/CMakeFiles/colmap.dir/ui/license_widget.cc.o\n",
      "[75/127] Building CXX object src/CMakeFiles/colmap.dir/exe/feature.cc.o\n",
      "[76/127] Building CXX object src/CMakeFiles/colmap.dir/ui/line_painter.cc.o\n",
      "[77/127] Building CXX object src/CMakeFiles/colmap.dir/ui/render_options.cc.o\n",
      "[78/127] Building CXX object src/CMakeFiles/colmap.dir/sfm/incremental_mapper.cc.o\n",
      "[79/127] Building CXX object src/CMakeFiles/colmap.dir/colmap_autogen/UYX5XTB5RZ/qrc_resources.cpp.o\n",
      "[80/127] Building CXX object src/CMakeFiles/colmap.dir/ui/point_painter.cc.o\n",
      "[81/127] Building CXX object src/CMakeFiles/colmap.dir/ui/options_widget.cc.o\n",
      "[82/127] Building CXX object src/CMakeFiles/colmap.dir/ui/log_widget.cc.o\n",
      "[83/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/coordinate_frame.cc.o\n",
      "[84/127] Building CXX object src/CMakeFiles/colmap.dir/ui/triangle_painter.cc.o\n",
      "[85/127] Building CXX object src/CMakeFiles/colmap.dir/exe/sfm.cc.o\n",
      "[86/127] Building CXX object src/CMakeFiles/colmap.dir/ui/automatic_reconstruction_widget.cc.o\n",
      "[87/127] Building CXX object src/CMakeFiles/colmap.dir/ui/reconstruction_manager_widget.cc.o\n",
      "[88/127] Building CXX object src/CMakeFiles/colmap.dir/ui/image_viewer_widget.cc.o\n",
      "[89/127] Building CXX object src/CMakeFiles/colmap.dir/ui/feature_extraction_widget.cc.o\n",
      "[90/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/homography_matrix.cc.o\n",
      "[91/127] Building CXX object src/CMakeFiles/colmap.dir/ui/qt_utils.cc.o\n",
      "[92/127] Building CXX object src/CMakeFiles/colmap.dir/ui/bundle_adjustment_widget.cc.o\n",
      "[93/127] Building CXX object src/CMakeFiles/colmap.dir/ui/match_matrix_widget.cc.o\n",
      "[94/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/database.cc.o\n",
      "[95/127] Building CXX object src/CMakeFiles/colmap.dir/ui/feature_matching_widget.cc.o\n",
      "[96/127] Building CXX object src/CMakeFiles/colmap.dir/ui/database_management_widget.cc.o\n",
      "[97/127] Building CXX object src/CMakeFiles/colmap.dir/ui/project_widget.cc.o\n",
      "[98/127] Building CXX object src/CMakeFiles/colmap.dir/ui/movie_grabber_widget.cc.o\n",
      "[99/127] Building CXX object src/CMakeFiles/colmap.dir/feature/sift.cc.o\n",
      "[100/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/generalized_relative_pose.cc.o\n",
      "[101/127] Building CXX object src/CMakeFiles/colmap.dir/ui/reconstruction_stats_widget.cc.o\n",
      "[102/127] Building CXX object src/CMakeFiles/colmap.dir/ui/dense_reconstruction_widget.cc.o\n",
      "[103/127] Building CXX object src/CMakeFiles/colmap.dir/util/option_manager.cc.o\n",
      "[104/127] Building CXX object src/CMakeFiles/colmap.dir/ui/reconstruction_options_widget.cc.o\n",
      "[105/127] Building CXX object src/CMakeFiles/colmap.dir/ui/main_window.cc.o\n",
      "[106/127] Building CXX object src/CMakeFiles/colmap.dir/ui/thread_control_widget.cc.o\n",
      "[107/127] Building CXX object src/CMakeFiles/colmap.dir/ui/point_viewer_widget.cc.o\n",
      "[108/127] Building CXX object src/CMakeFiles/colmap.dir/ui/render_options_widget.cc.o\n",
      "[109/127] Building CXX object src/CMakeFiles/colmap.dir/ui/undistortion_widget.cc.o\n",
      "[110/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/fundamental_matrix.cc.o\n",
      "[111/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/mvs.cc.o\n",
      "[112/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/colmap.cc.o\n",
      "[113/127] Building CXX object src/CMakeFiles/colmap.dir/ui/model_viewer_widget.cc.o\n",
      "[114/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/gui.cc.o\n",
      "[115/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/pose.cc.o\n",
      "[116/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/image.cc.o\n",
      "[117/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/feature.cc.o\n",
      "[118/127] Building CXX object src/CMakeFiles/colmap.dir/feature/matching.cc.o\n",
      "[119/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/essential_matrix.cc.o\n",
      "[120/127] Building CXX object src/CMakeFiles/colmap.dir/mvs/meshing.cc.o\n",
      "[121/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/model.cc.o\n",
      "[122/127] Building CXX object src/CMakeFiles/colmap.dir/optim/bundle_adjustment.cc.o\n",
      "[123/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/sfm.cc.o\n",
      "[124/127] Building CXX object src/CMakeFiles/colmap.dir/estimators/absolute_pose.cc.o\n",
      "[125/127] Linking CXX static library src/libcolmap.a\n",
      "[126/127] Building CXX object src/exe/CMakeFiles/colmap_exe.dir/vocab_tree.cc.o\n",
      "[127/127] Linking CXX executable src/exe/colmap\n",
      "/usr/bin/ld: warning: libglog.so.0, needed by /usr/lib/libceres.so.1.14.0, may conflict with libglog.so.1\n",
      "[0/1] Install the project...\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /usr/local/include/colmap\n",
      "-- Installing: /usr/local/include/colmap/estimators\n",
      "-- Installing: /usr/local/include/colmap/estimators/similarity_transform.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/essential_matrix_poly.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/two_view_geometry.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/triangulation.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/pose.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/utils.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/euclidean_transform.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/generalized_absolute_pose.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/essential_matrix_coeffs.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/absolute_pose.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/translation_transform.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/essential_matrix.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/generalized_relative_pose.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/affine_transform.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/generalized_absolute_pose_coeffs.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/fundamental_matrix.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/coordinate_frame.h\n",
      "-- Installing: /usr/local/include/colmap/estimators/homography_matrix.h\n",
      "-- Installing: /usr/local/include/colmap/base\n",
      "-- Installing: /usr/local/include/colmap/base/similarity_transform.h\n",
      "-- Installing: /usr/local/include/colmap/base/graph_cut.h\n",
      "-- Installing: /usr/local/include/colmap/base/database.h\n",
      "-- Installing: /usr/local/include/colmap/base/triangulation.h\n",
      "-- Installing: /usr/local/include/colmap/base/warp.h\n",
      "-- Installing: /usr/local/include/colmap/base/reconstruction_manager.h\n",
      "-- Installing: /usr/local/include/colmap/base/point2d.h\n",
      "-- Installing: /usr/local/include/colmap/base/pose.h\n",
      "-- Installing: /usr/local/include/colmap/base/polynomial.h\n",
      "-- Installing: /usr/local/include/colmap/base/reconstruction.h\n",
      "-- Installing: /usr/local/include/colmap/base/image_reader.h\n",
      "-- Installing: /usr/local/include/colmap/base/projection.h\n",
      "-- Installing: /usr/local/include/colmap/base/database_cache.h\n",
      "-- Installing: /usr/local/include/colmap/base/camera.h\n",
      "-- Installing: /usr/local/include/colmap/base/undistortion.h\n",
      "-- Installing: /usr/local/include/colmap/base/scene_clustering.h\n",
      "-- Installing: /usr/local/include/colmap/base/visibility_pyramid.h\n",
      "-- Installing: /usr/local/include/colmap/base/essential_matrix.h\n",
      "-- Installing: /usr/local/include/colmap/base/camera_database.h\n",
      "-- Installing: /usr/local/include/colmap/base/camera_models.h\n",
      "-- Installing: /usr/local/include/colmap/base/cost_functions.h\n",
      "-- Installing: /usr/local/include/colmap/base/point3d.h\n",
      "-- Installing: /usr/local/include/colmap/base/track.h\n",
      "-- Installing: /usr/local/include/colmap/base/correspondence_graph.h\n",
      "-- Installing: /usr/local/include/colmap/base/gps.h\n",
      "-- Installing: /usr/local/include/colmap/base/camera_rig.h\n",
      "-- Installing: /usr/local/include/colmap/base/image.h\n",
      "-- Installing: /usr/local/include/colmap/base/line.h\n",
      "-- Installing: /usr/local/include/colmap/base/homography_matrix.h\n",
      "-- Installing: /usr/local/include/colmap/feature\n",
      "-- Installing: /usr/local/include/colmap/feature/utils.h\n",
      "-- Installing: /usr/local/include/colmap/feature/sift.h\n",
      "-- Installing: /usr/local/include/colmap/feature/types.h\n",
      "-- Installing: /usr/local/include/colmap/feature/matching.h\n",
      "-- Installing: /usr/local/include/colmap/feature/extraction.h\n",
      "-- Installing: /usr/local/include/colmap/sfm\n",
      "-- Installing: /usr/local/include/colmap/sfm/incremental_triangulator.h\n",
      "-- Installing: /usr/local/include/colmap/sfm/incremental_mapper.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval\n",
      "-- Installing: /usr/local/include/colmap/retrieval/vote_and_verify.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/utils.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/inverted_index.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/visual_index.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/inverted_file_entry.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/inverted_file.h\n",
      "-- Installing: /usr/local/include/colmap/retrieval/geometry.h\n",
      "-- Installing: /usr/local/include/colmap/controllers\n",
      "-- Installing: /usr/local/include/colmap/controllers/hierarchical_mapper.h\n",
      "-- Installing: /usr/local/include/colmap/controllers/incremental_mapper.h\n",
      "-- Installing: /usr/local/include/colmap/controllers/automatic_reconstruction.h\n",
      "-- Installing: /usr/local/include/colmap/controllers/bundle_adjustment.h\n",
      "-- Installing: /usr/local/include/colmap/mvs\n",
      "-- Installing: /usr/local/include/colmap/mvs/cuda_flip.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/cuda_texture.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/patch_match_cuda.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/model.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/cuda_transpose.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/consistency_graph.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/normal_map.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/workspace.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/depth_map.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/gpu_mat_ref_image.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/gpu_mat_prng.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/cuda_rotate.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/patch_match.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/meshing.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/fusion.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/gpu_mat.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/image.h\n",
      "-- Installing: /usr/local/include/colmap/mvs/mat.h\n",
      "-- Installing: /usr/local/include/colmap/tools\n",
      "-- Installing: /usr/local/include/colmap/ui\n",
      "-- Installing: /usr/local/include/colmap/ui/reconstruction_manager_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/render_options.h\n",
      "-- Installing: /usr/local/include/colmap/ui/automatic_reconstruction_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/reconstruction_stats_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/database_management_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/feature_extraction_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/point_painter.h\n",
      "-- Installing: /usr/local/include/colmap/ui/project_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/model_viewer_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/license_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/media\n",
      "-- Installing: /usr/local/include/colmap/ui/line_painter.h\n",
      "-- Installing: /usr/local/include/colmap/ui/options_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/triangle_painter.h\n",
      "-- Installing: /usr/local/include/colmap/ui/thread_control_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/image_viewer_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/movie_grabber_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/match_matrix_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/point_viewer_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/feature_matching_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/main_window.h\n",
      "-- Installing: /usr/local/include/colmap/ui/log_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/qt_utils.h\n",
      "-- Installing: /usr/local/include/colmap/ui/dense_reconstruction_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/bundle_adjustment_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/colormaps.h\n",
      "-- Installing: /usr/local/include/colmap/ui/reconstruction_options_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/render_options_widget.h\n",
      "-- Installing: /usr/local/include/colmap/ui/shaders\n",
      "-- Installing: /usr/local/include/colmap/ui/undistortion_widget.h\n",
      "-- Installing: /usr/local/include/colmap/util\n",
      "-- Installing: /usr/local/include/colmap/util/logging.h\n",
      "-- Installing: /usr/local/include/colmap/util/camera_specs.h\n",
      "-- Installing: /usr/local/include/colmap/util/string.h\n",
      "-- Installing: /usr/local/include/colmap/util/math.h\n",
      "-- Installing: /usr/local/include/colmap/util/bitmap.h\n",
      "-- Installing: /usr/local/include/colmap/util/cudacc.h\n",
      "-- Installing: /usr/local/include/colmap/util/misc.h\n",
      "-- Installing: /usr/local/include/colmap/util/version.h\n",
      "-- Installing: /usr/local/include/colmap/util/opengl_utils.h\n",
      "-- Installing: /usr/local/include/colmap/util/cuda.h\n",
      "-- Installing: /usr/local/include/colmap/util/matrix.h\n",
      "-- Installing: /usr/local/include/colmap/util/cache.h\n",
      "-- Installing: /usr/local/include/colmap/util/types.h\n",
      "-- Installing: /usr/local/include/colmap/util/threading.h\n",
      "-- Installing: /usr/local/include/colmap/util/ply.h\n",
      "-- Installing: /usr/local/include/colmap/util/alignment.h\n",
      "-- Installing: /usr/local/include/colmap/util/sqlite3_utils.h\n",
      "-- Installing: /usr/local/include/colmap/util/endian.h\n",
      "-- Installing: /usr/local/include/colmap/util/option_manager.h\n",
      "-- Installing: /usr/local/include/colmap/util/testing.h\n",
      "-- Installing: /usr/local/include/colmap/util/random.h\n",
      "-- Installing: /usr/local/include/colmap/util/timer.h\n",
      "-- Installing: /usr/local/include/colmap/exe\n",
      "-- Installing: /usr/local/include/colmap/exe/sfm.h\n",
      "-- Installing: /usr/local/include/colmap/exe/database.h\n",
      "-- Installing: /usr/local/include/colmap/exe/feature.h\n",
      "-- Installing: /usr/local/include/colmap/exe/model.h\n",
      "-- Installing: /usr/local/include/colmap/exe/gui.h\n",
      "-- Installing: /usr/local/include/colmap/exe/mvs.h\n",
      "-- Installing: /usr/local/include/colmap/exe/image.h\n",
      "-- Installing: /usr/local/include/colmap/exe/vocab_tree.h\n",
      "-- Installing: /usr/local/include/colmap/optim\n",
      "-- Installing: /usr/local/include/colmap/optim/loransac.h\n",
      "-- Installing: /usr/local/include/colmap/optim/combination_sampler.h\n",
      "-- Installing: /usr/local/include/colmap/optim/sampler.h\n",
      "-- Installing: /usr/local/include/colmap/optim/sprt.h\n",
      "-- Installing: /usr/local/include/colmap/optim/ransac.h\n",
      "-- Installing: /usr/local/include/colmap/optim/support_measurement.h\n",
      "-- Installing: /usr/local/include/colmap/optim/least_absolute_deviations.h\n",
      "-- Installing: /usr/local/include/colmap/optim/bundle_adjustment.h\n",
      "-- Installing: /usr/local/include/colmap/optim/progressive_sampler.h\n",
      "-- Installing: /usr/local/include/colmap/optim/random_sampler.h\n",
      "-- Installing: /usr/local/include/colmap/lib\n",
      "-- Installing: /usr/local/include/colmap/lib/LSD\n",
      "-- Installing: /usr/local/include/colmap/lib/LSD/lsd.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/homkermap.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/mathop_sse2.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/svmdataset.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/float.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/aib.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/scalespace.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/mathop.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/imopv.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/svm.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/gmm.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/heap-def.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/qsort-def.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/fisher.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/quickshift.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/sift.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/array.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/rodrigues.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/kdtree.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/liop.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/slic.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/host.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/ikmeans.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/getopt_long.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/mathop_avx.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/covdet.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/lbp.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/stringop.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/generic.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/vlad.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/kmeans.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/mser.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/dsift.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/imopv_sse2.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/hog.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/shuffle-def.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/hikmeans.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/pgm.h\n",
      "-- Installing: /usr/local/include/colmap/lib/VLFeat/random.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/SurfaceTrimmer.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Geometry.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/PPolynomial.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MAT.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/FunctionData.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Octree.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Polynomial.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/SparseMatrix.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/CmdLineParser.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/CmdLineParser.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.IsoSurface.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/PointStream.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Hash.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Ply.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Allocator.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/BinaryNode.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/BSplineData.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.System.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MAT.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.WeightedSamples.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Polynomial.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Array.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/BSplineData.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/SparseMatrix.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MyTime.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Octree.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.SortedTreeNodes.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.Evaluation.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/PointStream.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Array.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MarchingCubes.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/FunctionData.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Geometry.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/PoissonRecon.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MultiGridOctreeData.inl\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/MemoryUsage.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/Factor.h\n",
      "-- Installing: /usr/local/include/colmap/lib/PoissonRecon/PPolynomial.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/LiteWindow.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ProgramGLSL.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/CLTexImage.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/PyramidCL.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ProgramGPU.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/PyramidGL.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ProgramCG.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ProgramCU.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/SiftMatch.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ShaderMan.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/GLTexImage.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/SiftGPU.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/GlobalUtil.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/FrameBufferObject.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/SiftPyramid.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/CuTexImage.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/PyramidCU.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/SiftMatchCU.h\n",
      "-- Installing: /usr/local/include/colmap/lib/SiftGPU/ProgramCL.h\n",
      "-- Installing: /usr/local/share/colmap/COLMAPConfig.cmake\n",
      "-- Installing: /usr/local/share/colmap/COLMAPConfigVersion.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindGlew.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindMetis.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindEigen3.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindFreeImage.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindGlog.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindLZ4.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindSQLite3.cmake\n",
      "-- Installing: /usr/local/share/colmap/cmake/FindFLANN.cmake\n",
      "-- Installing: /usr/local/share/applications/COLMAP.desktop\n",
      "-- Installing: /usr/local/lib/colmap/liblsd.a\n",
      "-- Installing: /usr/local/lib/colmap/libpoisson_recon.a\n",
      "-- Installing: /usr/local/lib/colmap/libsift_gpu.a\n",
      "-- Installing: /usr/local/lib/colmap/libvlfeat.a\n",
      "-- Installing: /usr/local/lib/colmap/libcolmap.a\n",
      "-- Installing: /usr/local/lib/colmap/libcolmap_cuda.a\n",
      "-- Installing: /usr/local/bin/colmap\n",
      "-- Set runtime path of \"/usr/local/bin/colmap\" to \"\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/pycolmap\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: pycolmap\n",
      "  Attempting uninstall: pycolmap\n",
      "    Found existing installation: pycolmap 0.3.0\n",
      "    Uninstalling pycolmap-0.3.0:\n",
      "      Successfully uninstalled pycolmap-0.3.0\n",
      "  Running setup.py develop for pycolmap\n",
      "Successfully installed pycolmap-0.4.0\n",
      "\n",
      "Processing /kaggle/input/omegaconf222py3/antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Processing /kaggle/input/omegaconf222py3/omegaconf-2.2.2-py3-none-any.whl\n",
      "Processing /kaggle/input/hydracore120py3/hydra_core-1.2.0-py3-none-any.whl\n",
      "Processing /kaggle/input/loguru006py3/loguru-0.6.0-py3-none-any.whl\n",
      "Installing collected packages: hydra-core, antlr4-python3-runtime, omegaconf, loguru\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.2.0 loguru-0.6.0 omegaconf-2.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from silk-keypoint-library) (from versions: 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1)\n",
      "ERROR: No matching distribution found for torch==1.11.0+cu113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/facebookresearch-silk\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: loguru>=0.5 in /opt/conda/lib/python3.7/site-packages (from SiLK-Keypoint-Library==1.0) (0.6.0)\n",
      "Collecting autoflake>=1.4\n",
      "  Downloading autoflake-2.1.1-py3-none-any.whl (31 kB)\n",
      "Collecting black==21.10b0\n",
      "  Downloading black-21.10b0-py3-none-any.whl (150 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.1/150.1 kB 19.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.7/site-packages (from SiLK-Keypoint-Library==1.0) (3.5.3)\n",
      "Collecting pdoc3>=0.10\n",
      "  Downloading pdoc3-0.10.0-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.7/135.7 kB 29.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: hydra-core==1.2.0 in /opt/conda/lib/python3.7/site-packages (from SiLK-Keypoint-Library==1.0) (1.2.0)\n",
      "Collecting omegaconf==2.2.3\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 16.3 MB/s eta 0:00:00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/hierarchical-localization-my\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.1 in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (1.13.0)\n",
      "Requirement already satisfied: torchvision>=0.3 in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (0.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (1.21.6)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (4.5.4.60)\n",
      "Requirement already satisfied: tqdm>=4.36.0 in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (4.64.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (3.5.3)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (5.13.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (1.7.3)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (3.8.0)\n",
      "Requirement already satisfied: pycolmap>=0.3.0 in ./pycolmap (from hloc==1.3) (0.4.0)\n",
      "Requirement already satisfied: kornia>=0.6.7 in /opt/conda/lib/python3.7/site-packages (from hloc==1.3) (0.6.11)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from kornia>=0.6.7->hloc==1.3) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.1->hloc==1.3) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3->hloc==1.3) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.3->hloc==1.3) (9.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown->hloc==1.3) (3.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown->hloc==1.3) (4.11.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown->hloc==1.3) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->hloc==1.3) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->hloc==1.3) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->hloc==1.3) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->hloc==1.3) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->hloc==1.3) (4.38.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->hloc==1.3) (8.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown->hloc==1.3) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.3->hloc==1.3) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.3->hloc==1.3) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.3->hloc==1.3) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.3->hloc==1.3) (1.26.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.3->hloc==1.3) (1.7.1)\n",
      "Installing collected packages: gdown, hloc\n",
      "  Running setup.py develop for hloc\n",
      "Successfully installed gdown-4.7.1 hloc-1.3\n",
      "\n",
      "installing openibl\n",
      "installing netvlad\n",
      "installing openibl_src\n"
     ]
    }
   ],
   "source": [
    "# %%capture captured\n",
    "%cd /kaggle/working\n",
    "\n",
    "# General utilities\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from fastprogress import progress_bar\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import Optional, Tuple, List\n",
    "import traceback\n",
    "import subprocess\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from functools import lru_cache\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# CV/ML\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from PIL import Image\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from torch import multiprocessing as mp\n",
    "\n",
    "\n",
    "def internet_available(host=\"8.8.8.8\", port=53, timeout=1):\n",
    "    # https://stackoverflow.com/a/33117579\n",
    "    import socket\n",
    "    try:\n",
    "        socket.setdefaulttimeout(timeout)\n",
    "        socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect((host, port))\n",
    "        return True\n",
    "    except socket.error as ex:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def run_sh(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "    print(out.decode('utf-8').strip())\n",
    "    \n",
    "    \n",
    "def install_from_input_directory(dirname):\n",
    "    src_dir = f'/kaggle/input/{dirname}/'\n",
    "    install_dir = os.path.realpath(f'./{dirname}/')\n",
    "    assert os.path.isdir(src_dir)\n",
    "    if not os.path.isdir(install_dir):\n",
    "        shutil.copytree(src_dir, install_dir)\n",
    "\n",
    "    if dirname.endswith('silk'):\n",
    "        if os.path.isfile(f'{install_dir}/silk'):\n",
    "            os.remove(f'{install_dir}/silk')\n",
    "        if not os.path.isdir(f'{install_dir}/silk'):\n",
    "            shutil.copytree(f'{install_dir}/lib', f'{install_dir}/silk')\n",
    "            \n",
    "    os.system(f'pip install -e {install_dir}')\n",
    "    if install_dir not in sys.path:\n",
    "        sys.path.append(install_dir)\n",
    "    \n",
    "    \n",
    "def install_hloc_local_features():\n",
    "    weights = {\n",
    "        'openibl': {\n",
    "            'src': '/kaggle/input/hloc-local-feature-weights/vgg16_netvlad.pth',\n",
    "            'dst': '/root/.cache/torch/hub/checkpoints/vgg16_netvlad.pth',\n",
    "        },\n",
    "        'netvlad': {\n",
    "            'src': '/kaggle/input/hloc-local-feature-weights/Pitts30K_struct.mat',\n",
    "            'dst': '/root/.cache/torch/hub/netvlad/VGG16-NetVLAD-Pitts30K.mat'\n",
    "        },\n",
    "        'openibl_src': {\n",
    "            'src': '/kaggle/input/openibl-zipball/yxgeee-OpenIBL-f3ef4fb',\n",
    "            'dst': '/root/.cache/torch/hub/yxgeee_OpenIBL_master'\n",
    "        }\n",
    "    }\n",
    "    for alg in weights.keys():\n",
    "        print('installing', alg)\n",
    "        w = weights[alg]\n",
    "        if os.path.isfile(w['src']):\n",
    "            os.makedirs(os.path.dirname(w['dst']), exist_ok=True)\n",
    "            shutil.copyfile(w['src'], w['dst'])\n",
    "        elif os.path.isdir(w['src']):\n",
    "            if os.path.isdir(w['dst']):\n",
    "                shutil.rmtree(w['dst'])\n",
    "            shutil.copytree(w['src'], w['dst'])\n",
    "            \n",
    "def install_pycolmap():\n",
    "    colmap_input_dir = '/kaggle/input/colmap'\n",
    "    colmap_install_dir = '/kaggle/working/colmap'\n",
    "\n",
    "    if not os.path.isdir(colmap_install_dir):\n",
    "        shutil.copytree(colmap_input_dir, colmap_install_dir)\n",
    "    os.system(f'''cd {colmap_install_dir}/build && \\\n",
    "        cmake .. -GNinja -DCMAKE_CUDA_ARCHITECTURES=native && \\\n",
    "        ninja && \\\n",
    "        ninja install\n",
    "        ''')\n",
    "\n",
    "    pycolmap_input_dir = '/kaggle/input/pycolmap'\n",
    "    pycolmap_install_dir = '/kaggle/working/pycolmap'\n",
    "    if not os.path.isdir(pycolmap_install_dir):\n",
    "        shutil.copytree(pycolmap_input_dir, pycolmap_install_dir)\n",
    "    os.system(f'pip install -e {pycolmap_install_dir}')\n",
    "    if pycolmap_install_dir not in sys.path:\n",
    "        sys.path.append(pycolmap_install_dir)\n",
    "\n",
    "            \n",
    "# install custom colmap build\n",
    "install_pycolmap()\n",
    "import pycolmap\n",
    "\n",
    "            \n",
    "# install dependencies for SiLK\n",
    "!pip install --no-deps \\\n",
    "    /kaggle/input/omegaconf222py3/antlr4_python3_runtime-4.9.3-py3-none-any.whl \\\n",
    "    /kaggle/input/omegaconf222py3/omegaconf-2.2.2-py3-none-any.whl \\\n",
    "    /kaggle/input/hydracore120py3/hydra_core-1.2.0-py3-none-any.whl \\\n",
    "    /kaggle/input/loguru006py3/loguru-0.6.0-py3-none-any.whl\n",
    "\n",
    "\n",
    "install_from_input_directory('facebookresearch-silk')\n",
    "\n",
    "from silk.backbones.superpoint.vgg import ParametricVGG\n",
    "from silk.backbones.silk.silk import SiLKVGG as SiLK\n",
    "from silk.backbones.silk.silk import from_feature_coords_to_image_coords\n",
    "from silk.config.model import load_model_from_checkpoint\n",
    "from silk.models.silk import matcher\n",
    "\n",
    "\n",
    "# install hloc and weights\n",
    "install_from_input_directory('hierarchical-localization-my')\n",
    "install_hloc_local_features()\n",
    "\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "from hloc import extract_features as hloc_extract_features\n",
    "from hloc import pairs_from_retrieval as hloc_pairs_from_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71e53b0-1c53-49ab-ad2a-03ab27c75881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name\t: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz\n",
      "cpu MHz\t\t: 1200.099\n",
      "cpu cores\t: 18\n",
      "MemTotal:       263818860 kB\n",
      "Kornia version: 0.6.11\n",
      "Pycolmap version: 0.4.0\n",
      "Internet access: True\n",
      "{'debug': True,\n",
      " 'device': device(type='cuda'),\n",
      " 'exhaustive_if_less': 10,\n",
      " 'geometric_verification_alg': 'magsac',\n",
      " 'input_filepath': '/kaggle/input/image-matching-challenge-2023/train/train_labels.csv',\n",
      " 'local_feature': 'LoFTR',\n",
      " 'matching_alg': 'smnn',\n",
      " 'output_filepath': 'submission.csv',\n",
      " 'retrieval_alg': 'openibl',\n",
      " 'retrieval_per_img': 10,\n",
      " 'scenes_to_debug': ('bike',),\n",
      " 'src_dirname': '/kaggle/input/image-matching-challenge-2023',\n",
      " 'test_or_train': 'train',\n",
      " 'use_all_imgs': True}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Option:\n",
    "    test_or_train: str = 'train' # Can be train, or test\n",
    "    device: object = torch.device('cuda')\n",
    "    src_dirname: str = '/kaggle/input/image-matching-challenge-2023'\n",
    "    input_filepath: Optional[str] = None\n",
    "    output_filepath: str = 'submission.csv'\n",
    "    use_all_imgs: bool = True\n",
    "    debug: bool = True\n",
    "    scenes_to_debug: Tuple[str] = None\n",
    "    \n",
    "    local_feature: str = 'LoFTR' # ['LoFTR, 'DISK', \"SiLK\", \"DISKLoFTR\"]\n",
    "    matching_alg: str = 'smnn' # ['smnn', 'adalam']\n",
    "    retrieval_alg: str = 'openibl' # ['exhaustive', netvlad', 'openibl', 'cosplace']\n",
    "    geometric_verification_alg: str = 'magsac' # ['colmap', 'magsac']\n",
    "        \n",
    "    retrieval_per_img: int = 10\n",
    "    exhaustive_if_less: int = 10\n",
    "        \n",
    "    def __init__(self):\n",
    "        #self.scenes_to_debug = ('kyiv-puppet-theater', )\n",
    "        #self.scenes_to_debug = ('dioscuri', )\n",
    "        self.scenes_to_debug = ('bike', )\n",
    "\n",
    "        if self.test_or_train == 'train':\n",
    "            self.input_filepath = f'{self.src_dirname}/train/train_labels.csv'\n",
    "        else:\n",
    "            self.input_filepath = f'{self.src_dirname}/sample_submission.csv'\n",
    "            self.scenes_to_debug = None\n",
    "            self.debug = False\n",
    "        \n",
    "\n",
    "run_sh('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n",
    "run_sh('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n",
    "run_sh('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n",
    "run_sh('cat /proc/meminfo | egrep \"^MemTotal\"')\n",
    "    \n",
    "print('Kornia version:', K.__version__)\n",
    "print('Pycolmap version:', pycolmap.__version__)\n",
    "print('Internet access:', internet_available())\n",
    "\n",
    "opt = Option()\n",
    "pprint(asdict(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ffb8c3-a89e-46bf-bc9e-2c410a51191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_str(a):\n",
    "    return ';'.join([str(x) for x in a.reshape(-1)])\n",
    "\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.image_to_tensor(cv2.imread(fname), False).float() / 255.\n",
    "    img = K.color.bgr_to_rgb(img.to(device))\n",
    "    return img\n",
    "\n",
    "def train_only(fn):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        if opt.test_or_train == 'train':\n",
    "            return fn(*args, **kwargs)\n",
    "    return wrapped\n",
    "def preprocess(img, max_long_side=640, to_gray=False, padding_required=False):\n",
    "    B, C, H, W = img.shape\n",
    "    long_side = max(H, W)\n",
    "    scale = 1.0\n",
    "    if max_long_side > 0 and long_side > max_long_side:\n",
    "        img = K.geometry.resize(img, max_long_side, side='long', antialias=True)\n",
    "        scale = max_long_side / long_side\n",
    "        long_side = max_long_side\n",
    "        *_, H, W = img.shape\n",
    "    if padding_required:\n",
    "        padded = torch.zeros((B, C, long_side, long_side), dtype=img.dtype, device=img.device)\n",
    "        padded[..., :H, :W] = img\n",
    "        img = padded\n",
    "    if to_gray:\n",
    "        img = K.color.rgb_to_grayscale(img)\n",
    "    return img, scale\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_fnames, long_side=640, padding=False, to_gray=False, device=torch.device('cpu')):\n",
    "        self.img_fnames = np.array(img_fnames)\n",
    "        self.long_side = long_side\n",
    "        self.padding = padding\n",
    "        self.to_gray = to_gray\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = load_torch_image(self.img_fnames[idx], device=self.device)\n",
    "        img, scale = preprocess(img, self.long_side, self.to_gray, self.padding)\n",
    "        img = img.squeeze(0)\n",
    "        return img, scale\n",
    "    \n",
    "class ImagePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_ds, index_pairs):\n",
    "        self.img_ds = img_ds\n",
    "        self.index_pairs = np.array(index_pairs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx1, idx2 = self.index_pairs[idx].tolist()\n",
    "        img1, scale1 = self.img_ds[idx1]\n",
    "        img2, scale2 = self.img_ds[idx2]\n",
    "        return idx1, img1, scale1, idx2, img2, scale2\n",
    "        \n",
    "def get_image_pair_loader(img_fnames, index_pairs, long_side=640, padding=False, to_gray=False, device=torch.device('cpu')):\n",
    "    image_ds = ImageDataset(img_fnames, long_side, padding, to_gray)\n",
    "    pairs_ds = ImagePairDataset(image_ds, index_pairs)\n",
    "    return torch.utils.data.DataLoader(pairs_ds, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be79774b-6df6-4d46-a98e-5bd43500a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use ViT global descriptor to get matching shortlists.\n",
    "def get_global_desc(fnames, model,\n",
    "                    device =  torch.device('cpu')):\n",
    "    model = model.eval()\n",
    "    model= model.to(device)\n",
    "    config = resolve_data_config({}, model=model)\n",
    "    transform = create_transform(**config)\n",
    "    global_descs_convnext=[]\n",
    "    for i, img_fname_full in tqdm(enumerate(fnames),total= len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        img = Image.open(img_fname_full).convert('RGB')\n",
    "        timg = transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            desc = model.forward_features(timg.to(device)).mean(dim=(-1,2))#\n",
    "            #print (desc.shape)\n",
    "            desc = desc.view(1, -1)\n",
    "            desc_norm = F.normalize(desc, dim=1, p=2)\n",
    "        #print (desc_norm)\n",
    "        global_descs_convnext.append(desc_norm.detach().cpu())\n",
    "    global_descs_all = torch.cat(global_descs_convnext, dim=0)\n",
    "    return global_descs_all\n",
    "\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i+1, len(img_fnames)):\n",
    "            index_pairs.append((i,j))\n",
    "    return index_pairs\n",
    "\n",
    "def hloc_image_pairs_shortlist(img_dir, fnames, alg='netvlad', match_per_img=20, exhaustive_if_less=20):\n",
    "    if len(fnames) <= 20 or alg == 'exhaustive':\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "\n",
    "    tmp_filepath = os.path.basename(img_dir)\n",
    "    retrieval_conf = hloc_extract_features.confs[alg]\n",
    "    input_path = Path(img_dir)\n",
    "    tmp_path = Path(f'./{img_dir}_{alg}')\n",
    "    if os.path.isdir(tmp_path):\n",
    "        shutil.rmtree(tmp_path)\n",
    "    global_descriptors = hloc_extract_features.main(retrieval_conf, input_path, tmp_path)\n",
    "    loc_pairs = tmp_path / \"loc_pairs.txt\"\n",
    "    hloc_pairs_from_retrieval.main(global_descriptors, loc_pairs, num_matched=match_per_img)\n",
    "    img_index = {os.path.basename(f): i for i, f in enumerate(fnames)}\n",
    "    pairs = []\n",
    "    with open(loc_pairs, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            img1, img2 = line.strip().split()\n",
    "            if img1 not in img_index or img2 not in img_index:\n",
    "                continue\n",
    "            idx1, idx2 = img_index[img1], img_index[img2]\n",
    "            pairs.append(tuple(sorted([idx1, idx2])))\n",
    "    return sorted(set(pairs))\n",
    "\n",
    "def get_image_pairs_shortlist(fnames,\n",
    "                              sim_th = 0.6, # should be strict\n",
    "                              min_pairs = 20,\n",
    "                              exhaustive_if_less = 20,\n",
    "                              device=torch.device('cpu')):\n",
    "    num_imgs = len(fnames)\n",
    "\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "\n",
    "    model = timm.create_model('tf_efficientnet_b7',\n",
    "                              checkpoint_path='/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b7/1/tf_efficientnet_b7_ra-6c08e654.pth')\n",
    "    model.eval()\n",
    "    descs = get_global_desc(fnames, model, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "    # removing half\n",
    "    mask = dm <= sim_th\n",
    "    total = 0\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    already_there_set = []\n",
    "    for st_idx in range(num_imgs-1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]  \n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < 1000:\n",
    "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
    "                total+=1\n",
    "    matching_list = sorted(list(set(matching_list)))\n",
    "    return matching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e520b7-a65d-4481-9adc-58a4236b18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to manipulate a colmap database.\n",
    "# Forked from https://github.com/colmap/colmap/blob/dev/scripts/python/database.py\n",
    "\n",
    "# Copyright (c) 2018, ETH Zurich and UNC Chapel Hill.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#\n",
    "#     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of\n",
    "#       its contributors may be used to endorse or promote products derived\n",
    "#       from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "# Author: Johannes L. Schoenberger (jsch-at-demuc-dot-de)\n",
    "\n",
    "# This script is based on an original implementation by True Price.\n",
    "\n",
    "import sys\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "IS_PYTHON3 = sys.version_info[0] >= 3\n",
    "\n",
    "MAX_IMAGE_ID = 2**31 - 1\n",
    "\n",
    "CREATE_CAMERAS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS cameras (\n",
    "    camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    model INTEGER NOT NULL,\n",
    "    width INTEGER NOT NULL,\n",
    "    height INTEGER NOT NULL,\n",
    "    params BLOB,\n",
    "    prior_focal_length INTEGER NOT NULL)\"\"\"\n",
    "\n",
    "CREATE_DESCRIPTORS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS descriptors (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\"\"\"\n",
    "\n",
    "CREATE_IMAGES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS images (\n",
    "    image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    name TEXT NOT NULL UNIQUE,\n",
    "    camera_id INTEGER NOT NULL,\n",
    "    prior_qw REAL,\n",
    "    prior_qx REAL,\n",
    "    prior_qy REAL,\n",
    "    prior_qz REAL,\n",
    "    prior_tx REAL,\n",
    "    prior_ty REAL,\n",
    "    prior_tz REAL,\n",
    "    CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {}),\n",
    "    FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))\n",
    "\"\"\".format(MAX_IMAGE_ID)\n",
    "\n",
    "CREATE_TWO_VIEW_GEOMETRIES_TABLE = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS two_view_geometries (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    config INTEGER NOT NULL,\n",
    "    F BLOB,\n",
    "    E BLOB,\n",
    "    H BLOB)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_KEYPOINTS_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS keypoints (\n",
    "    image_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB,\n",
    "    FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)\n",
    "\"\"\"\n",
    "\n",
    "CREATE_MATCHES_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS matches (\n",
    "    pair_id INTEGER PRIMARY KEY NOT NULL,\n",
    "    rows INTEGER NOT NULL,\n",
    "    cols INTEGER NOT NULL,\n",
    "    data BLOB)\"\"\"\n",
    "\n",
    "CREATE_NAME_INDEX = \\\n",
    "    \"CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)\"\n",
    "\n",
    "CREATE_ALL = \"; \".join([\n",
    "    CREATE_CAMERAS_TABLE,\n",
    "    CREATE_IMAGES_TABLE,\n",
    "    CREATE_KEYPOINTS_TABLE,\n",
    "    CREATE_DESCRIPTORS_TABLE,\n",
    "    CREATE_MATCHES_TABLE,\n",
    "    CREATE_TWO_VIEW_GEOMETRIES_TABLE,\n",
    "    CREATE_NAME_INDEX\n",
    "])\n",
    "\n",
    "\n",
    "def image_ids_to_pair_id(image_id1, image_id2):\n",
    "    if image_id1 > image_id2:\n",
    "        image_id1, image_id2 = image_id2, image_id1\n",
    "    return image_id1 * MAX_IMAGE_ID + image_id2\n",
    "\n",
    "\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % MAX_IMAGE_ID\n",
    "    image_id1 = (pair_id - image_id2) // MAX_IMAGE_ID\n",
    "    return image_id1, image_id2\n",
    "\n",
    "\n",
    "def array_to_blob(array):\n",
    "    if IS_PYTHON3:\n",
    "        return array.tobytes()\n",
    "    else:\n",
    "        return np.getbuffer(array)\n",
    "\n",
    "\n",
    "def blob_to_array(blob, dtype, shape=(-1,)):\n",
    "    if IS_PYTHON3:\n",
    "        return np.frombuffer(blob, dtype=dtype).reshape(*shape)\n",
    "    else:\n",
    "        return np.frombuffer(blob, dtype=dtype).reshape(*shape)\n",
    "\n",
    "\n",
    "class COLMAPDatabase(sqlite3.Connection):\n",
    "\n",
    "    @staticmethod\n",
    "    def connect(database_path):\n",
    "        return sqlite3.connect(database_path, factory=COLMAPDatabase)\n",
    "\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(COLMAPDatabase, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.create_tables = lambda: self.executescript(CREATE_ALL)\n",
    "        self.create_cameras_table = \\\n",
    "            lambda: self.executescript(CREATE_CAMERAS_TABLE)\n",
    "        self.create_descriptors_table = \\\n",
    "            lambda: self.executescript(CREATE_DESCRIPTORS_TABLE)\n",
    "        self.create_images_table = \\\n",
    "            lambda: self.executescript(CREATE_IMAGES_TABLE)\n",
    "        self.create_two_view_geometries_table = \\\n",
    "            lambda: self.executescript(CREATE_TWO_VIEW_GEOMETRIES_TABLE)\n",
    "        self.create_keypoints_table = \\\n",
    "            lambda: self.executescript(CREATE_KEYPOINTS_TABLE)\n",
    "        self.create_matches_table = \\\n",
    "            lambda: self.executescript(CREATE_MATCHES_TABLE)\n",
    "        self.create_name_index = lambda: self.executescript(CREATE_NAME_INDEX)\n",
    "\n",
    "    def add_camera(self, model, width, height, params,\n",
    "                   prior_focal_length=False, camera_id=None):\n",
    "        params = np.asarray(params, np.float64)\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO cameras VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "            (camera_id, model, width, height, array_to_blob(params),\n",
    "             prior_focal_length))\n",
    "        return cursor.lastrowid\n",
    "\n",
    "    def add_image(self, name, camera_id,\n",
    "                  prior_q=np.zeros(4), prior_t=np.zeros(3), image_id=None):\n",
    "        cursor = self.execute(\n",
    "            \"INSERT INTO images VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (image_id, name, camera_id, prior_q[0], prior_q[1], prior_q[2],\n",
    "             prior_q[3], prior_t[0], prior_t[1], prior_t[2]))\n",
    "        return cursor.lastrowid\n",
    "    \n",
    "    def get_image(self, image_id):\n",
    "        cursor = self.execute(f\"SELECT * FROM images WHERE image_id = {image_id}\")\n",
    "        return cursor.fetchone()                         \n",
    "\n",
    "    def add_keypoints(self, image_id, keypoints):\n",
    "        assert(len(keypoints.shape) == 2)\n",
    "        assert(keypoints.shape[1] in [2, 4, 6])\n",
    "\n",
    "        keypoints = np.asarray(keypoints, np.float32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO keypoints VALUES (?, ?, ?, ?)\",\n",
    "            (image_id,) + keypoints.shape + (array_to_blob(keypoints),))\n",
    "    \n",
    "    def get_keypoints(self, image_id):\n",
    "        cursor = self.execute(f'SELECT * FROM keypoints WHERE image_id = {image_id}')\n",
    "        _, rows, cols, blob = cursor.fetchone()\n",
    "        keypoints = blob_to_array(blob, np.float32, (rows, cols))\n",
    "        return keypoints\n",
    "\n",
    "    def add_descriptors(self, image_id, descriptors):\n",
    "        descriptors = np.ascontiguousarray(descriptors, np.uint8)\n",
    "        self.execute(\n",
    "            \"INSERT INTO descriptors VALUES (?, ?, ?, ?)\",\n",
    "            (image_id,) + descriptors.shape + (array_to_blob(descriptors),))\n",
    "\n",
    "    def add_matches(self, image_id1, image_id2, matches):\n",
    "        assert(len(matches.shape) == 2)\n",
    "        assert(matches.shape[1] == 2)\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:,::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        self.execute(\n",
    "            \"INSERT INTO matches VALUES (?, ?, ?, ?)\",\n",
    "            (pair_id,) + matches.shape + (array_to_blob(matches),))\n",
    "        \n",
    "    def get_all_matches(self):\n",
    "        for row in self.execute('SELECT * FROM matches'):\n",
    "            pair_id, rows, cols, matches_blob = row\n",
    "            if matches_blob is None:\n",
    "                continue\n",
    "            idx1, idx2 = pair_id_to_image_ids(pair_id)\n",
    "            matches = blob_to_array(matches_blob, np.uint32, (rows, cols))\n",
    "            yield idx1, idx2, matches\n",
    "    \n",
    "    def get_matches(self, image_id1, image_id2):\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        cursor = self.execute(f'SELECT * FROM matches WHERE pair_id = {pair_id}')\n",
    "        _, rows, cols, blob = cursor.fetchone()\n",
    "        matches = blob_to_array(blob, np.uint32, (rows, cols))\n",
    "        return matches\n",
    "            \n",
    "    def add_two_view_geometry(self, image_id1, image_id2, matches,\n",
    "                              F=np.zeros((3, 3)), E=np.zeros((3, 3)), H=np.zeros((3, 3)), config=2):\n",
    "        assert(len(matches.shape) == 2)\n",
    "        assert(matches.shape[1] == 2)\n",
    "\n",
    "        if image_id1 > image_id2:\n",
    "            matches = matches[:,::-1]\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        matches = np.asarray(matches, np.uint32)\n",
    "        F = np.asarray(F, dtype=np.float64)\n",
    "        E = np.asarray(E, dtype=np.float64)\n",
    "        H = np.asarray(H, dtype=np.float64)\n",
    "        self.execute(\n",
    "            \"INSERT INTO two_view_geometries VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (pair_id,) + matches.shape + (array_to_blob(matches), config,\n",
    "             array_to_blob(F), array_to_blob(E), array_to_blob(H)))\n",
    "    \n",
    "    def get_two_view_geometry(self, image_id1, image_id2):\n",
    "        pair_id = image_ids_to_pair_id(image_id1, image_id2)\n",
    "        cursor = self.execute(f'SELECT * FROM two_view_geometries WHERE pair_id = {pair_id}')\n",
    "        try:\n",
    "            (_, matches_rows, matches_cols, matches_blob, config,\n",
    "              F_blob, E_blob, H_blob, qvec_blob, tvec_blob) = cursor.fetchone()\n",
    "        except:\n",
    "            raise KeyError\n",
    "        \n",
    "        matches = blob_to_array(matches_blob, np.uint32, (matches_rows, matches_cols))\n",
    "        F = blob_to_array(F_blob, np.float64, (3, 3))\n",
    "        return matches, F, config\n",
    "\n",
    "def draw_matches(img1, kp1, img2, kp2, matches, mask=None):\n",
    "    match_img = cv2.drawMatchesKnn(\n",
    "        img1, cv2.KeyPoint.convert(kp1), \n",
    "        img2, cv2.KeyPoint.convert(kp2), \n",
    "        [(cv2.DMatch(qry, obj, 0, 0), cv2.DMatch(qry, obj, 0, 0)) \n",
    "         for qry, obj in matches],\n",
    "        None,\n",
    "        singlePointColor=(255, 0, 0),\n",
    "        matchColor=(0, 255, 0),\n",
    "        matchesMask=[[i, 0] for i in mask.reshape(-1)] if mask is not None else None,\n",
    "        flags=0)\n",
    "    plt.figure(figsize=[12, 12])\n",
    "    plt.imshow(match_img)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "\n",
    "def geometric_verification_magsac(database_path, min_inliers=15):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    for idx1, idx2, matches in db.get_all_matches():\n",
    "        kp1 = db.get_keypoints(idx1)[matches[:, 0]]\n",
    "        kp2 = db.get_keypoints(idx2)[matches[:, 1]]\n",
    "        _, img1, *_ = db.get_image(idx1)\n",
    "        _, img2, *_ = db.get_image(idx2)\n",
    "\n",
    "        F, mask = cv2.findFundamentalMat(kp1, kp2, cv2.USAC_MAGSAC, 2.0, 0.99999, 1000)\n",
    "        inlier_matches = np.stack([matches[i] \n",
    "                                   for i, v in enumerate(mask.flatten()) if v == 1])\n",
    "        n_inliers = mask.sum()\n",
    "        print(f'vefiried ({idx1}-{idx2}) {n_inliers} / {len(mask)}')\n",
    "        if n_inliers < min_inliers:\n",
    "            continue\n",
    "            # db.add_two_view_geometry(idx1, idx2, matches=inlier_matches, F=F, config=1)\n",
    "        else:\n",
    "            db.add_two_view_geometry(idx1, idx2, matches=inlier_matches, F=F, config=3)\n",
    "    db.commit()\n",
    "    db.close()\n",
    "    del db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce0ff51-c203-4310-b5b8-bd60a7d805c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to interface DISK with Colmap.\n",
    "# Forked from https://github.com/cvlab-epfl/disk/blob/37f1f7e971cea3055bb5ccfc4cf28bfd643fa339/colmap/h5_to_db.py\n",
    "\n",
    "#  Copyright [2020] [Michał Tyszkiewicz, Pascal Fua, Eduard Trulls]\n",
    "#\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "\n",
    "import os, argparse, h5py, warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "\n",
    "def get_focal(image_path, err_on_default=False):\n",
    "    image         = Image.open(image_path)\n",
    "    max_size      = max(image.size)\n",
    "\n",
    "    exif = image.getexif()\n",
    "    focal = None\n",
    "    if exif is not None:\n",
    "        focal_35mm = None\n",
    "        # https://github.com/colmap/colmap/blob/d3a29e203ab69e91eda938d6e56e1c7339d62a99/src/util/bitmap.cc#L299\n",
    "        for tag, value in exif.items():\n",
    "            focal_35mm = None\n",
    "            if ExifTags.TAGS.get(tag, None) == 'FocalLengthIn35mmFilm':\n",
    "                focal_35mm = float(value)\n",
    "                break\n",
    "\n",
    "        if focal_35mm is not None:\n",
    "            focal = focal_35mm / 35. * max_size\n",
    "    \n",
    "    if focal is None:\n",
    "        if err_on_default:\n",
    "            raise RuntimeError(\"Failed to find focal length\")\n",
    "\n",
    "        # failed to find it in exif, use prior\n",
    "        FOCAL_PRIOR = 1.2\n",
    "        focal = FOCAL_PRIOR * max_size\n",
    "\n",
    "    return focal\n",
    "\n",
    "def create_camera(db, image_path, camera_model):\n",
    "    image         = Image.open(image_path)\n",
    "    width, height = image.size\n",
    "\n",
    "    focal = get_focal(image_path)\n",
    "\n",
    "    if camera_model == 'simple-pinhole':\n",
    "        model = 0 # simple pinhole\n",
    "        param_arr = np.array([focal, width / 2, height / 2])\n",
    "    if camera_model == 'pinhole':\n",
    "        model = 1 # pinhole\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2])\n",
    "    elif camera_model == 'simple-radial':\n",
    "        model = 2 # simple radial\n",
    "        param_arr = np.array([focal, width / 2, height / 2, 0.1])\n",
    "    elif camera_model == 'opencv':\n",
    "        model = 4 # opencv\n",
    "        param_arr = np.array([focal, focal, width / 2, height / 2, 0., 0., 0., 0.])\n",
    "         \n",
    "    return db.add_camera(model, width, height, param_arr)\n",
    "\n",
    "\n",
    "def add_keypoints(db, h5_path, image_path, img_ext, camera_model, single_camera = True):\n",
    "    keypoint_f = h5py.File(os.path.join(h5_path, 'keypoints.h5'), 'r')\n",
    "\n",
    "    camera_id = None\n",
    "    fname_to_id = {}\n",
    "    for filename in tqdm(list(keypoint_f.keys())):\n",
    "        keypoints = keypoint_f[filename][..., :2]\n",
    "\n",
    "        fname_with_ext = filename# + img_ext\n",
    "        path = os.path.join(image_path, fname_with_ext)\n",
    "        if not os.path.isfile(path):\n",
    "            raise IOError(f'Invalid image path {path}')\n",
    "\n",
    "        if camera_id is None or not single_camera:\n",
    "            camera_id = create_camera(db, path, camera_model)\n",
    "        image_id = db.add_image(fname_with_ext, camera_id)\n",
    "        fname_to_id[filename] = image_id\n",
    "        \n",
    "        db.add_keypoints(image_id, keypoints)\n",
    "\n",
    "    return fname_to_id\n",
    "\n",
    "def add_matches(db, h5_path, fname_to_id):\n",
    "    match_file = h5py.File(os.path.join(h5_path, 'matches.h5'), 'r')\n",
    "    \n",
    "    added = set()\n",
    "    n_keys = len(match_file.keys())\n",
    "    n_total = (n_keys * (n_keys - 1)) // 2\n",
    "\n",
    "    with tqdm(total=n_total) as pbar:\n",
    "        for key_1 in match_file.keys():\n",
    "            group = match_file[key_1]\n",
    "            for key_2 in group.keys():\n",
    "                id_1 = fname_to_id[key_1]\n",
    "                id_2 = fname_to_id[key_2]\n",
    "\n",
    "                pair_id = image_ids_to_pair_id(id_1, id_2)\n",
    "                if pair_id in added:\n",
    "                    warnings.warn(f'Pair {pair_id} ({id_1}, {id_2}) already added!')\n",
    "                    continue\n",
    "            \n",
    "                matches = group[key_2][()]\n",
    "                db.add_matches(id_1, id_2, matches)\n",
    "\n",
    "                added.add(pair_id)\n",
    "\n",
    "                pbar.update(1)\n",
    "            db.commit()\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473a6566-0c4f-4177-87fd-098bed8d0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making kornia local features loading w/o internet\n",
    "class KeyNetAffNetHardNet(KF.LocalFeature):\n",
    "    \"\"\"Convenience module, which implements KeyNet detector + AffNet + HardNet descriptor.\n",
    "\n",
    "    .. image:: _static/img/keynet_affnet.jpg\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 5000,\n",
    "        upright: bool = False,\n",
    "        device = torch.device('cpu'),\n",
    "        scale_laf: float = 1.0,\n",
    "    ):\n",
    "        ori_module = KF.PassLAF() if upright else KF.LAFOrienter(angle_detector=KF.OriNet(False)).eval()\n",
    "        if not upright:\n",
    "            weights = torch.load('/kaggle/input/kornia-local-feature-weights/OriNet.pth')['state_dict']\n",
    "            ori_module.angle_detector.load_state_dict(weights)\n",
    "        detector = KF.KeyNetDetector(\n",
    "            False, num_features=num_features, ori_module=ori_module, aff_module=KF.LAFAffNetShapeEstimator(False).eval()\n",
    "        ).to(device)\n",
    "        kn_weights = torch.load('/kaggle/input/kornia-local-feature-weights/keynet_pytorch.pth')['state_dict']\n",
    "        detector.model.load_state_dict(kn_weights)\n",
    "        affnet_weights = torch.load('/kaggle/input/kornia-local-feature-weights/AffNet.pth')['state_dict']\n",
    "        detector.aff.load_state_dict(affnet_weights)\n",
    "        \n",
    "        hardnet = KF.HardNet(False).eval()\n",
    "        hn_weights = torch.load('/kaggle/input/kornia-local-feature-weights/HardNetLib.pth')['state_dict']\n",
    "        hardnet.load_state_dict(hn_weights)\n",
    "        descriptor = KF.LAFDescriptor(hardnet, patch_size=32, grayscale_descriptor=True).to(device)\n",
    "        super().__init__(detector, descriptor, scale_laf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286f0899-614d-48db-a16d-8d176b220ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_features(img_fnames,\n",
    "                    num_feats = 2048,\n",
    "                    upright = False,\n",
    "                    device=torch.device('cpu'),\n",
    "                    feature_dir = '.featureout',\n",
    "                    resize_small_edge_to = 600):\n",
    "    if opt.local_feature == 'DISK':\n",
    "        # Load DISK from Kaggle models so it can run when the notebook is offline.\n",
    "        disk = KF.DISK().to(device)\n",
    "        pretrained_dict = torch.load(\n",
    "            '/kaggle/input/disk/pytorch/depth-supervision/1/loftr_outdoor.ckpt', \n",
    "            map_location=opt.device)\n",
    "        disk.load_state_dict(pretrained_dict['extractor'])\n",
    "        disk.eval()\n",
    "    elif opt.local_feature == 'KeyNetAffNetHardNet':\n",
    "        feature = KeyNetAffNetHardNet(num_feats, upright, opt.device).to(opt.device).eval()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "    with h5py.File(f'{feature_dir}/lafs.h5', mode='w') as f_laf, \\\n",
    "         h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
    "        for img_path in progress_bar(img_fnames):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "            with torch.inference_mode():\n",
    "                timg = load_torch_image(img_path, device=opt.device)\n",
    "                H, W = timg.shape[2:]\n",
    "                if resize_small_edge_to is None:\n",
    "                    timg_resized = timg\n",
    "                else:\n",
    "                    timg_resized = K.geometry.resize(\n",
    "                        timg, resize_small_edge_to, antialias=True)\n",
    "                    print(f'Resized {timg.shape} to {timg_resized.shape} (resize_small_edge_to={resize_small_edge_to})')\n",
    "                h, w = timg_resized.shape[2:]\n",
    "                if opt.local_feature == 'DISK':\n",
    "                    features = disk(timg_resized, num_feats, pad_if_not_divisible=True)[0]\n",
    "                    kps1, descs = features.keypoints, features.descriptors\n",
    "                    \n",
    "                    lafs = KF.laf_from_center_scale_ori(\n",
    "                        kps1[None], \n",
    "                        torch.ones(1, len(kps1), 1, 1, device=opt.device))\n",
    "                if opt.local_feature == 'KeyNetAffNetHardNet':\n",
    "                    lafs, resps, descs = feature(K.color.rgb_to_grayscale(timg_resized))\n",
    "                lafs[:,:,0,:] *= float(W) / float(w)\n",
    "                lafs[:,:,1,:] *= float(H) / float(h)\n",
    "                desc_dim = descs.shape[-1]\n",
    "                kpts = KF.get_laf_center(lafs).reshape(-1, 2).detach().cpu().numpy()\n",
    "                descs = descs.reshape(-1, desc_dim).detach().cpu().numpy()\n",
    "                f_laf[key] = lafs.detach().cpu().numpy()\n",
    "                f_kp[key] = kpts\n",
    "                f_desc[key] = descs\n",
    "    return\n",
    "\n",
    "def detect_features_disk(img_fnames,\n",
    "                    num_feats = 8192,\n",
    "                    device=torch.device('cpu'),\n",
    "                    feature_dir='.featureout',\n",
    "                    max_long_side=1600,\n",
    "                    num_octaves=4):\n",
    "    # Load DISK from Kaggle models so it can run when the notebook is offline.\n",
    "    disk = KF.DISK().to(device)\n",
    "    pretrained_dict = torch.load(\n",
    "        '/kaggle/input/disk/pytorch/depth-supervision/1/loftr_outdoor.ckpt', \n",
    "        map_location=opt.device)\n",
    "    disk.load_state_dict(pretrained_dict['extractor'])\n",
    "    disk.eval()\n",
    "    \n",
    "    img_ds = ImageDataset(img_fnames, \n",
    "                          long_side=max_long_side,\n",
    "                          padding=False,\n",
    "                          to_gray=False,\n",
    "                          device=device)\n",
    "    img_loader = torch.utils.data.DataLoader(img_ds)\n",
    "\n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "        \n",
    "    with h5py.File(f'{feature_dir}/lafs.h5', mode='w') as f_laf, \\\n",
    "         h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
    "\n",
    "        for img_path, (img, scale) in zip(tqdm(img_fnames, desc='feat_ext'), img_loader):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "            scale = scale.to(img.device)\n",
    "            h, w = img.shape[-2:]\n",
    "            num_feats_target = num_feats\n",
    "            lafs_multiscale = []\n",
    "            kpts_multiscale = []\n",
    "            desc_multiscale = []\n",
    "            with torch.inference_mode():\n",
    "                for octave in range(num_octaves):\n",
    "                    if octave > 0:\n",
    "                        h, w = h // 2, w // 2\n",
    "                        img = K.geometry.resize(img, (h, w), interpolation='area')\n",
    "                        num_feats_target //= 4\n",
    "                        scale /= 2.0\n",
    "                    features = disk(img, num_feats_target, pad_if_not_divisible=True)[0]\n",
    "                    kps1, descs = features.keypoints, features.descriptors\n",
    "                    lafs = KF.laf_from_center_scale_ori(\n",
    "                        kps1[None], \n",
    "                        torch.ones(1, len(kps1), 1, 1, device=opt.device) / scale)\n",
    "                    lafs[:,:,0,:] /= scale\n",
    "                    lafs[:,:,1,:] /= scale\n",
    "                    desc_dim = descs.shape[-1]\n",
    "                    kpts = KF.get_laf_center(lafs).reshape(-1, 2).detach().cpu().numpy()\n",
    "                    descs = descs.reshape(-1, desc_dim).detach().cpu().numpy()\n",
    "                    lafs_multiscale.append(lafs.detach().cpu().numpy())\n",
    "                    kpts_multiscale.append(kpts)\n",
    "                    desc_multiscale.append(descs)\n",
    "            f_laf[key] = np.concatenate(lafs_multiscale, axis=1)\n",
    "            f_kp[key] = np.concatenate(kpts_multiscale)\n",
    "            f_desc[key] = np.concatenate(desc_multiscale)\n",
    "    return\n",
    "\n",
    "def get_unique_idxs(A, dim=0):\n",
    "    # https://stackoverflow.com/questions/72001505/how-to-get-unique-elements-and-their-firstly-appeared-indices-of-a-pytorch-tenso\n",
    "    unique, idx, counts = torch.unique(A, dim=dim, sorted=True, return_inverse=True, return_counts=True)\n",
    "    _, ind_sorted = torch.sort(idx, stable=True)\n",
    "    cum_sum = counts.cumsum(0)\n",
    "    cum_sum = torch.cat((torch.tensor([0],device=cum_sum.device), cum_sum[:-1]))\n",
    "    first_indices = ind_sorted[cum_sum]\n",
    "    return first_indices\n",
    "\n",
    "def match_features(img_fnames,\n",
    "                   index_pairs,\n",
    "                   feature_dir = '.featureout',\n",
    "                   device=torch.device('cpu'),\n",
    "                   min_matches=15, \n",
    "                   force_mutual = True,\n",
    "                   matching_alg='smnn'\n",
    "                  ):\n",
    "    assert matching_alg in ['smnn', 'adalam']\n",
    "    with h5py.File(f'{feature_dir}/lafs.h5', mode='r') as f_laf, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
    "        h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "\n",
    "        for pair_idx in progress_bar(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            lafs1 = torch.from_numpy(f_laf[key1][...]).to(device)\n",
    "            lafs2 = torch.from_numpy(f_laf[key2][...]).to(device)\n",
    "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
    "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
    "            if matching_alg == 'adalam':\n",
    "                img1, img2 = cv2.imread(fname1), cv2.imread(fname2)\n",
    "                hw1, hw2 = img1.shape[:2], img2.shape[:2]\n",
    "                adalam_config = KF.adalam.get_adalam_default_config()\n",
    "                #adalam_config['orientation_difference_threshold'] = None\n",
    "                #adalam_config['scale_rate_threshold'] = None\n",
    "                adalam_config['force_seed_mnn']= False\n",
    "                adalam_config['search_expansion'] = 16\n",
    "                adalam_config['ransac_iters'] = 128\n",
    "                adalam_config['device'] = device\n",
    "                dists, idxs = KF.match_adalam(desc1, desc2,\n",
    "                                              lafs1, lafs2, # Adalam takes into account also geometric information\n",
    "                                              hw1=hw1, hw2=hw2,\n",
    "                                              config=adalam_config) # Adalam also benefits from knowing image size\n",
    "            else:\n",
    "                dists, idxs = KF.match_smnn(desc1, desc2, 0.98)\n",
    "            if len(idxs)  == 0:\n",
    "                continue\n",
    "            # Force mutual nearest neighbors\n",
    "            if force_mutual:\n",
    "                first_indices = get_unique_idxs(idxs[:,1])\n",
    "                idxs = idxs[first_indices]\n",
    "                dists = dists[first_indices]\n",
    "            n_matches = len(idxs)\n",
    "            if True:\n",
    "                print (f'{key1} - {key2}: {n_matches} matches')\n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                 group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n",
    "    return\n",
    "\n",
    "def match_loftr(img_fnames,\n",
    "                   index_pairs,\n",
    "                   feature_dir = '.featureout_loftr',\n",
    "                   device=torch.device('cpu'),\n",
    "                   min_matches=15, \n",
    "                max_long_side=800):\n",
    "    matcher = KF.LoFTR(pretrained=None)\n",
    "    matcher.load_state_dict(torch.load('/kaggle/input/loftr/pytorch/outdoor/1/loftr_outdoor.ckpt')['state_dict'])\n",
    "    matcher = matcher.to(device).eval()\n",
    "    \n",
    "    print(f'{feature_dir}/matches_loftr.h5')\n",
    "    \n",
    "    prev_key1, prev_key2 = None, None\n",
    "    # First we do pairwise matching, and then extract \"keypoints\" from loftr matches.\n",
    "    with h5py.File(f'{feature_dir}/matches_loftr.h5', mode='w') as f_match:\n",
    "        for idx1, idx2 in progress_bar(index_pairs):\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            \n",
    "            if key1 != prev_key1:\n",
    "                img1 = load_torch_image(fname1, device=device)\n",
    "                img1, scale1 = preprocess(img1, max_long_side, True, True)\n",
    "                prev_key1 = key1\n",
    "                \n",
    "            if key2 != prev_key2:\n",
    "                img2 = load_torch_image(fname2, device=device)\n",
    "                img2, scale2 = preprocess(img2, max_long_side, True, True)\n",
    "                prev_key2 = key2 \n",
    "                \n",
    "            with torch.inference_mode():\n",
    "                fwd_matches = matcher({\"image0\": img1,\"image1\": img2})\n",
    "                bwd_matches = matcher({\"image0\": img2,\"image1\": img1})\n",
    "\n",
    "            mkpts1 = torch.cat([fwd_matches['keypoints0'], bwd_matches['keypoints1']])\n",
    "            mkpts1 = (mkpts1 / scale1).cpu().numpy()\n",
    "            \n",
    "            mkpts2 = torch.cat([fwd_matches['keypoints1'], bwd_matches['keypoints0']])\n",
    "            mkpts2 = (mkpts2 / scale2).cpu().numpy()\n",
    "            \n",
    "            n_matches = len(mkpts1)\n",
    "            group = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                 group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1))\n",
    "            gc.collect()\n",
    "\n",
    "    # Let's find unique loftr pixels and group them together.\n",
    "    kpts = defaultdict(list)\n",
    "    match_indexes = defaultdict(dict)\n",
    "    total_kpts = defaultdict(int)\n",
    "    with h5py.File(f'{feature_dir}/matches_loftr.h5', mode='r') as f_match:\n",
    "        for k1 in f_match.keys():\n",
    "            group = f_match[k1]\n",
    "            for k2 in group.keys():\n",
    "                matches = group[k2][...]\n",
    "                total_kpts[k1]\n",
    "                kpts[k1].append(matches[:, :2])\n",
    "                kpts[k2].append(matches[:, 2:])\n",
    "                current_match = torch.arange(len(matches)).reshape(-1, 1).repeat(1, 2)\n",
    "                current_match[:, 0] += total_kpts[k1]\n",
    "                current_match[:, 1] += total_kpts[k2]\n",
    "                total_kpts[k1] += len(matches)\n",
    "                total_kpts[k2] += len(matches)\n",
    "                match_indexes[k1][k2] = current_match\n",
    "\n",
    "    orig_kpts = deepcopy(kpts)\n",
    "    for k in kpts.keys():\n",
    "        kpts[k] = np.round(np.concatenate(kpts[k], axis=0))\n",
    "        orig_kpts[k] = np.concatenate(orig_kpts[k], axis=0)\n",
    "    \n",
    "    unique_kpts = {}\n",
    "    unique_match_idxs = {}\n",
    "    out_match = defaultdict(dict)\n",
    "    \n",
    "    for k in kpts.keys():\n",
    "        average_duplicated_points = True\n",
    "        if average_duplicated_points:\n",
    "            uniq_kps, uniq_reverse_idxs, uniq_cnts = torch.unique(\n",
    "                torch.from_numpy(kpts[k]), dim=0, \n",
    "                return_inverse=True, return_counts=True)\n",
    "            mean_kps = torch.zeros_like(uniq_kps, dtype=torch.float32)\n",
    "            for i in range(len(kpts[k])):\n",
    "                mean_kps[uniq_reverse_idxs[i]] += orig_kpts[k][i]\n",
    "            mean_kps /= uniq_cnts.type(mean_kps.dtype).unsqueeze(-1)\n",
    "            unique_match_idxs[k] = uniq_reverse_idxs\n",
    "            unique_kpts[k] = mean_kps.numpy()\n",
    "        else:\n",
    "            uniq_kps, uniq_reverse_idxs = torch.unique(\n",
    "                torch.from_numpy(kpts[k]),dim=0, return_inverse=True)\n",
    "            unique_match_idxs[k] = uniq_reverse_idxs\n",
    "            unique_kpts[k] = uniq_kps.numpy()\n",
    "        \n",
    "    for k1, group in match_indexes.items():\n",
    "        for k2, m in group.items():\n",
    "            m2 = deepcopy(m)\n",
    "            m2[:,0] = unique_match_idxs[k1][m2[:,0]]\n",
    "            m2[:,1] = unique_match_idxs[k2][m2[:,1]]\n",
    "            mkpts = np.concatenate([unique_kpts[k1][m2[:,0]],\n",
    "                                    unique_kpts[k2][m2[:,1]],\n",
    "                                   ],\n",
    "                                   axis=1)\n",
    "            unique_idxs_current = get_unique_idxs(torch.from_numpy(mkpts), dim=0)\n",
    "            m2_semiclean = m2[unique_idxs_current]\n",
    "            unique_idxs_current1 = get_unique_idxs(m2_semiclean[:, 0], dim=0)\n",
    "            m2_semiclean = m2_semiclean[unique_idxs_current1]\n",
    "            unique_idxs_current2 = get_unique_idxs(m2_semiclean[:, 1], dim=0)\n",
    "            m2_semiclean2 = m2_semiclean[unique_idxs_current2]\n",
    "            out_match[k1][k2] = m2_semiclean2.numpy()\n",
    "            \n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp:\n",
    "        for k, kpts1 in unique_kpts.items():\n",
    "            f_kp[k] = kpts1\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        for k1, gr in out_match.items():\n",
    "            group  = f_match.require_group(k1)\n",
    "            for k2, match in gr.items():\n",
    "                group[k2] = match\n",
    "    return\n",
    "\n",
    "def import_into_colmap(img_dir,\n",
    "                       feature_dir ='.featureout',\n",
    "                       database_path = 'colmap.db',\n",
    "                       img_ext='.jpg'):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    #fname_to_id = add_keypoints(db, feature_dir, img_dir, img_ext, 'opencv', single_camera)\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, img_ext, 'simple-radial', single_camera)\n",
    "    add_matches(\n",
    "        db,\n",
    "        feature_dir,\n",
    "        fname_to_id,\n",
    "    )\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n",
    "    del db\n",
    "    return fname_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ce7481-3f83-4bab-b861-165c7a8b533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matcher(local_feature_type, feature_dir):\n",
    "    if local_feature_type == 'LoFTR':\n",
    "        return DetectAndMatchLoFTR(\n",
    "            feature_dir=feature_dir,\n",
    "            device=opt.device,\n",
    "            max_long_side=600)\n",
    "    elif local_feature_type == 'SiLK':\n",
    "        return DetectAndMatchSILK(\n",
    "            feature_dir=feature_dir, \n",
    "            device=opt.device, \n",
    "            max_long_side=840)\n",
    "    elif local_feature_type == 'DISKLoFTR':\n",
    "        return DetectAndMatchDiskLoftrHybrid( \n",
    "            num_feats=8192,\n",
    "            device=opt.device,\n",
    "            feature_dir=feature_dir,\n",
    "            max_long_side=1200,\n",
    "            min_matches=40,\n",
    "            num_octaves=4,\n",
    "            matching_alg=opt.matching_alg)\n",
    "    else:\n",
    "        return DetectAndMatchDefault(\n",
    "            num_feats=5000,\n",
    "            feature_dir=feature_dir,\n",
    "            device=opt.device,\n",
    "            upright=True,\n",
    "            resize_small_edge_to=800,\n",
    "            matching_alg=opt.matching_alg,\n",
    "            force_mutual=True,\n",
    "            min_matches=15)\n",
    "    \n",
    "\n",
    "class DetectAndMatch:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.time_detection = 0\n",
    "        self.time_matching = 0\n",
    "    \n",
    "    def process(self, img_fnames, index_pairs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "class DetectAndMatchDefault(DetectAndMatch):\n",
    "    def __init__(self, \n",
    "                 num_feats=2048,\n",
    "                 upright=False,\n",
    "                 device=torch.device('cpu'),\n",
    "                 feature_dir='.featureout',\n",
    "                 resize_small_edge_to=600,\n",
    "                 min_matches=15, \n",
    "                 force_mutual = True,\n",
    "                 matching_alg='smnn'):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.upright = upright\n",
    "        self.device = device\n",
    "        self.feature_dir = feature_dir\n",
    "        self.resize_small_edge_to = resize_small_edge_to\n",
    "        self.min_matches = 15\n",
    "        self.force_mutual = force_mutual\n",
    "        self.matching_alg = matching_alg\n",
    "    \n",
    "    def process(self, img_fnames, index_pairs):\n",
    "        t = time()\n",
    "        detect_features(img_fnames, \n",
    "                        self.num_feats,\n",
    "                        feature_dir=self.feature_dir,\n",
    "                        upright=self.upright,\n",
    "                        device=self.device,\n",
    "                        resize_small_edge_to=self.resize_small_edge_to,\n",
    "                       )\n",
    "        gc.collect()\n",
    "        self.time_detection = time() - t\n",
    "        \n",
    "        t = time()\n",
    "        match_features(img_fnames, \n",
    "                       index_pairs, \n",
    "                       feature_dir=self.feature_dir, \n",
    "                       device=self.device,\n",
    "                       matching_alg=self.matching_alg)\n",
    "        self.time_matching = time() - t\n",
    "        \n",
    "        \n",
    "class DetectAndMatchLoFTR(DetectAndMatch):\n",
    "    def __init__(self, feature_dir, device=torch.device('cpu'), max_long_side=800):\n",
    "        super().__init__()\n",
    "        self.feature_dir = feature_dir\n",
    "        self.device = device\n",
    "        self.max_long_side = max_long_side\n",
    "    \n",
    "    def process(self, img_fnames, index_pairs):\n",
    "        t = time()\n",
    "        match_loftr(img_fnames, index_pairs,\n",
    "                    feature_dir=self.feature_dir, \n",
    "                    device=self.device, \n",
    "                    max_long_side=self.max_long_side)\n",
    "        self.time_matching = time() - t\n",
    "\n",
    "        \n",
    "class DetectAndMatchSILK(DetectAndMatch):     \n",
    "    NMS = 0  # NMS radius, 0 = disabled\n",
    "    BORDER = 0  # remove detection on border, 0 = disabled\n",
    "    THRESHOLD = 1.0  # keypoint score thresholding, if # of keypoints is less than provided top-k, then will add keypoints to reach top-k value, 1.0 = disabled\n",
    "    TOP_K = 10000  # minimum number of best keypoints to output, could be higher if threshold specified above has low value\n",
    "\n",
    "    MATCHER_RATIO_THRESHOLD = 0.8\n",
    "    \n",
    "    DEFAULT_OUTPUTS = (\"sparse_positions\", \"sparse_descriptors\")\n",
    "    SCALE_FACTOR = 1.41  # scaling of descriptor output, do not change\n",
    "    CKPT_PATH = \"/kaggle/input/silk-local-feature-weights/silk/coco-rgb-aug.ckpt\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 feature_dir, \n",
    "                 multi_res = False,\n",
    "                 device=torch.device('cpu'), \n",
    "                 max_long_side=800,\n",
    "                 min_matches=15):\n",
    "        super().__init__()\n",
    "        self.feature_dir = feature_dir\n",
    "        self.multi_res = multi_res\n",
    "        self.device = device\n",
    "        self.max_long_side = max_long_side\n",
    "        self.min_matches = min_matches\n",
    "        \n",
    "    \n",
    "    def process(self, img_fnames, index_pairs):\n",
    "        t = time()\n",
    "        self.detect_features(img_fnames)\n",
    "        gc.collect()\n",
    "        self.time_detection = time() - t\n",
    "        \n",
    "        t = time()\n",
    "        self.match_features(img_fnames, index_pairs)\n",
    "        self.time_matching = time() - t\n",
    "        \n",
    "    def detect_features(self, img_fnames):\n",
    "        model = DetectAndMatchSILK.get_model(device=self.device)\n",
    "        img_ds = ImageDataset(img_fnames, \n",
    "                              long_side=self.max_long_side,\n",
    "                              padding=False,\n",
    "                              to_gray=True,\n",
    "                              device=self.device)\n",
    "        img_loader = torch.utils.data.DataLoader(img_ds)\n",
    "        if not os.path.isdir(self.feature_dir):\n",
    "            os.makedirs(self.feature_dir)\n",
    "        \n",
    "        with h5py.File(f'{self.feature_dir}/lafs.h5', mode='w') as f_laf, \\\n",
    "             h5py.File(f'{self.feature_dir}/keypoints.h5', mode='w') as f_kpts, \\\n",
    "             h5py.File(f'{self.feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
    "            for img_path, (img, scale) in zip(tqdm(img_fnames, desc='feat_ext'), img_loader):\n",
    "                img_fname = img_path.split('/')[-1]\n",
    "                key = img_fname\n",
    "                scale = scale.to(opt.device)\n",
    "                with torch.inference_mode():\n",
    "                    h, w = img.shape[-2:]\n",
    "                    kps, descs = model(img)\n",
    "                    kps = from_feature_coords_to_image_coords(model, kps)\n",
    "                    kps, descs = kps[0], descs[0]\n",
    "                    kps = kps / scale\n",
    "                    kps = kps[..., [1, 0]]\n",
    "                    \n",
    "                    desc_dim = descs.shape[-1]\n",
    "                    lafs = KF.laf_from_center_scale_ori(\n",
    "                        kps[None], \n",
    "                        torch.ones(1, len(kps), 1, 1, device=opt.device))\n",
    "                    f_laf[key] = lafs.detach().cpu().numpy()\n",
    "                    f_kpts[key] = kps.detach().cpu().numpy()\n",
    "                    f_desc[key] = descs.reshape(-1, desc_dim).detach().cpu().numpy()\n",
    "\n",
    "    def match_features(self, img_fnames, idx_pairs):\n",
    "        from silk.models.silk import matcher as Matcher\n",
    "        matcher = Matcher(postprocessing=\"ratio-test\", threshold=self.MATCHER_RATIO_THRESHOLD)\n",
    "        with h5py.File(f'{self.feature_dir}/keypoints.h5', mode='r') as f_kpts, \\\n",
    "             h5py.File(f'{self.feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
    "             h5py.File(f'{self.feature_dir}/matches.h5', mode='w') as f_match:\n",
    "            for idx1, idx2 in tqdm(idx_pairs, desc='matching'):\n",
    "                fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "                key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "                desc1 = torch.from_numpy(f_desc[key1][...]).to(self.device)\n",
    "                desc2 = torch.from_numpy(f_desc[key2][...]).to(self.device)\n",
    "                matches = matcher(desc1, desc2)\n",
    "                n_matches = matches.shape[0]\n",
    "                group  = f_match.require_group(key1)\n",
    "                if n_matches >= self.min_matches:\n",
    "                    group.create_dataset(\n",
    "                        key2, data=matches.detach().cpu().numpy().reshape(-1, 2))\n",
    "\n",
    "                \n",
    "    @classmethod\n",
    "    def get_model(cls, device=torch.device('cpu')):\n",
    "        backbone = ParametricVGG(\n",
    "            use_max_pooling=False,\n",
    "            padding=0,\n",
    "            normalization_fn=[torch.nn.BatchNorm2d(i) for i in (64, 64, 128, 128)],\n",
    "        )\n",
    "        # load model\n",
    "        model = SiLK(\n",
    "            in_channels=1,\n",
    "            backbone=backbone,\n",
    "            detection_threshold=cls.THRESHOLD,\n",
    "            detection_top_k=cls.TOP_K,\n",
    "            nms_dist=cls.NMS,\n",
    "            border_dist=cls.BORDER,\n",
    "            default_outputs=cls.DEFAULT_OUTPUTS,\n",
    "            descriptor_scale_factor=cls.SCALE_FACTOR,\n",
    "            padding=0,\n",
    "        )\n",
    "        model = load_model_from_checkpoint(\n",
    "            model,\n",
    "            checkpoint_path=cls.CKPT_PATH,\n",
    "            state_dict_fn=lambda x: {k[len(\"_mods.model.\") :]: v for k, v in x.items()},\n",
    "            device=device,\n",
    "            freeze=True,\n",
    "            eval=True,\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "class DetectAndMatchDiskLoftrHybrid(DetectAndMatch):\n",
    "    def __init__(self, \n",
    "                 num_feats=2048,\n",
    "                 device=torch.device('cpu'),\n",
    "                 feature_dir='.featureout',\n",
    "                 max_long_side=800,\n",
    "                 min_matches=15,\n",
    "                 num_octaves=1,\n",
    "                 matching_alg=\"smnn\"):\n",
    "        super().__init__()\n",
    "        self.num_feats = num_feats\n",
    "        self.device = device\n",
    "        self.feature_dir = feature_dir\n",
    "        self.max_long_side = max_long_side\n",
    "        self.min_matches = min_matches\n",
    "        self.num_octaves = num_octaves\n",
    "        self.matching_alg = matching_alg\n",
    "    \n",
    "    def process(self, img_fnames, index_pairs):\n",
    "        t = time()\n",
    "        detect_features_disk(img_fnames, \n",
    "                             self.num_feats,\n",
    "                             feature_dir=self.feature_dir,\n",
    "                             device=self.device,\n",
    "                             max_long_side=self.max_long_side,\n",
    "                             num_octaves=self.num_octaves)\n",
    "        gc.collect()\n",
    "        self.time_detection = time() - t\n",
    "        \n",
    "        t = time()\n",
    "        match_features(img_fnames, \n",
    "                       index_pairs, \n",
    "                       feature_dir=self.feature_dir, \n",
    "                       device=self.device,\n",
    "                       matching_alg=self.matching_alg)\n",
    "        self.time_matching = time() - t\n",
    "        \n",
    "    def match_features_loftr_guided(self, img_fnames, img_pairs):\n",
    "        match_features(img_fnames, \n",
    "                       index_pairs, \n",
    "                       feature_dir=self.feature_dir, \n",
    "                       device=self.device,\n",
    "                       matching_alg='smnn')\n",
    "        gc.collect()\n",
    "\n",
    "        loftr = KF.LoFTR(pretrained=None)\n",
    "        loftr.load_state_dict(torch.load('/kaggle/input/loftr/pytorch/outdoor/1/loftr_outdoor.ckpt')['state_dict'])\n",
    "        loftr = loftr.to(device).eval()\n",
    "        \n",
    "        prev_key1, prev_key2 = None, None\n",
    "        for idx1, idx2 in progress_bar(index_pairs):\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "\n",
    "            if key1 != prev_key1:\n",
    "                img1 = load_torch_image(fname1, device=device)\n",
    "                img1, scale1 = preprocess(img1, max_long_side, True, True)\n",
    "                prev_key1 = key1\n",
    "\n",
    "            if key2 != prev_key2:\n",
    "                img2 = load_torch_image(fname2, device=device)\n",
    "                img2, scale2 = preprocess(img2, max_long_side, True, True)\n",
    "                prev_key2 = key2 \n",
    "\n",
    "            with torch.inference_mode():\n",
    "                fwd_matches = matcher({\"image0\": img1,\"image1\": img2})\n",
    "                bwd_matches = matcher({\"image0\": img2,\"image1\": img1})\n",
    "\n",
    "            mkpts1 = torch.cat([fwd_matches['keypoints0'], bwd_matches['keypoints1']])\n",
    "            mkpts1 = (mkpts1 / scale1).cpu().numpy()\n",
    "\n",
    "            mkpts2 = torch.cat([fwd_matches['keypoints1'], bwd_matches['keypoints0']])\n",
    "            mkpts2 = (mkpts2 / scale2).cpu().numpy()\n",
    "\n",
    "            n_matches = len(mkpts1)\n",
    "            group  = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                 group.create_dataset(key2, data=np.concatenate([mkpts1, mkpts2], axis=1))\n",
    "            gc.collect()\n",
    "            \n",
    "        raise NotImplementedError\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864f73dd-0e8f-4417-984f-d4098657f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and opt.debug:\n",
    "    img_dir, img_fnames, *_ = load_img_fnames(data_dict, \"urban\", \"kyiv-puppet-theater\")\n",
    "    feature_dir = 'dbg'\n",
    "    detect_and_match = DetectAndMatchSILK(feature_dir, device=opt.device, max_long_side=800)\n",
    "    detect_and_match.process(img_fnames, ((0, 1), (1, 3), ))\n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kpts, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
    "         h5py.File(f'{feature_dir}/matches.h5', mode='r') as f_match:\n",
    "        for key1, group in f_match.items():\n",
    "            for key2, matches in group.items():\n",
    "                print(key1, key2)\n",
    "                kp1 = f_kpts[key1][...][..., :2]\n",
    "                kp2 = f_kpts[key2][...][..., :2]\n",
    "                img1 = cv2.imread(os.path.join(img_dir, key1))\n",
    "                img2 = cv2.imread(os.path.join(img_dir, key2))\n",
    "                draw_matches(img1, kp1, img2, kp2, matches, mask=None)\n",
    "                \n",
    "\n",
    "    print(detect_and_match.time_detection)\n",
    "    print(detect_and_match.time_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adedd13-b651-4f32-9477-5b29fdf02579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from csv.\n",
    "def read_submission_file():\n",
    "    data_dict = {}\n",
    "    with open(opt.input_filepath, 'r') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            # Skip header.\n",
    "            if l and i > 0:\n",
    "                if opt.test_or_train == 'train':\n",
    "                    dataset, scene, image, _, _ = l.strip().split(',')\n",
    "                else:\n",
    "                    image, dataset, scene, _, _ = l.strip().split(',')\n",
    "\n",
    "                if dataset not in data_dict:\n",
    "                    data_dict[dataset] = {}\n",
    "                if scene not in data_dict[dataset]:\n",
    "                    data_dict[dataset][scene] = []\n",
    "                data_dict[dataset][scene].append(image)\n",
    "    return data_dict\n",
    "\n",
    "      \n",
    "def load_img_fnames(data_dict, dataset, scene):\n",
    "    img_dir = f'{opt.src_dirname}/{opt.test_or_train}/{dataset}/{scene}/images'\n",
    "    if opt.test_or_train == 'train':\n",
    "        assert os.path.exists(img_dir)\n",
    "    elif not os.path.exists(img_dir):\n",
    "        return None, None, None, None\n",
    "            \n",
    "    # train directories have some extra images. Is it true also for test data?\n",
    "    img_fnames_ref = [f'{opt.src_dirname}/{opt.test_or_train}/{x}' \n",
    "                  for x in data_dict[dataset][scene]]\n",
    "    img_fnames_all = sorted(glob(f'{img_dir}/*'))\n",
    "    if len(img_fnames_ref) < len(img_fnames_all):\n",
    "        print(f'image count mismatch! {len(img_fnames_ref)} < {len(img_fnames_all)}')\n",
    "    if opt.use_all_imgs:\n",
    "        img_fnames = img_fnames_all\n",
    "    else:\n",
    "        img_fnames = img_fnames_ref\n",
    "    return img_dir, img_fnames, img_fnames_ref, img_fnames_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e3e7e8-21ed-4ad8-b656-fa2b6d950977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a submission file.\n",
    "def create_submission(out_results, data_dict):\n",
    "    with open(opt.output_filepath, 'w') as f:\n",
    "        f.write('image_path,dataset,scene,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in data_dict:\n",
    "            if dataset in out_results:\n",
    "                res = out_results[dataset]\n",
    "            else:\n",
    "                res = {}\n",
    "            for scene in data_dict[dataset]:\n",
    "                if scene in res:\n",
    "                    scene_res = res[scene]\n",
    "                else:\n",
    "                    scene_res = {\"R\":{}, \"t\":{}}\n",
    "                for image in data_dict[dataset][scene]:\n",
    "                    if image in scene_res:\n",
    "                        print (image)\n",
    "                        R = scene_res[image]['R'].reshape(-1)\n",
    "                        T = scene_res[image]['t'].reshape(-1)\n",
    "                    else:\n",
    "                        R = np.eye(3).reshape(-1)\n",
    "                        T = np.zeros((3))\n",
    "                    f.write(f'{image},{dataset},{scene},{arr_to_str(R)},{arr_to_str(T)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ccd4d7-7686-4ac3-9cab-30093b4b2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Debug:\n",
    "    index_pairs: list = field(default_factory=list) \n",
    "    img_fnames: list = field(default_factory=list) \n",
    "    img_dirname: str = None\n",
    "    recon_fnames: list = field(default_factory=list) \n",
    "    best_idx: int = -1\n",
    "    database_path: str = None\n",
    "    fname_to_id: dict = field(default_factory=dict)\n",
    "    output_path: str = None\n",
    "        \n",
    "@dataclass\n",
    "class Timing:\n",
    "    shortlisting: float = 0\n",
    "    feature_detection: float = 0\n",
    "    feature_matching: float = 0\n",
    "    geometric_verification: float = 0\n",
    "    reconstruction: float = 0\n",
    "  \n",
    "def process_scene(data_dict, dataset, scene, result_queue):\n",
    "    try:\n",
    "        results = {}\n",
    "        timing = Timing()\n",
    "        dbg = Debug() if opt.debug else None\n",
    "\n",
    "        img_dir, img_fnames, img_fnames_ref, img_fnames_all = load_img_fnames(\n",
    "            data_dict, dataset, scene)\n",
    "        if img_dir is None:\n",
    "            return\n",
    "        if dbg is not None:\n",
    "            dbg.img_dirname = img_dir\n",
    "                                     \n",
    "        print (f\"Got {len(img_fnames)} images\")\n",
    "        feature_dir = f'featureout/{dataset}_{scene}'\n",
    "        os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "        # step1. SHORTLISTING\n",
    "        t = time()\n",
    "        retrieval_per_img = min(opt.retrieval_per_img, max(1, len(img_fnames) - 1))\n",
    "        index_pairs = hloc_image_pairs_shortlist(img_dir, img_fnames, \n",
    "                                                 alg=opt.retrieval_alg,\n",
    "                                                 match_per_img=retrieval_per_img, \n",
    "                                                 exhaustive_if_less=opt.exhaustive_if_less)\n",
    "        if dbg is not None:\n",
    "            dbg.index_pairs = index_pairs\n",
    "            dbg.img_fnames = img_fnames\n",
    "        timing.shortlisting += time() - t\n",
    "        print (f'{len(index_pairs)}, pairs to match, {timing.shortlisting:.4f} sec')\n",
    "        gc.collect()\n",
    "\n",
    "        # step2. FEATURE DETECTION & MATCHING\n",
    "        detect_and_match = get_matcher(opt.local_feature, feature_dir)\n",
    "        detect_and_match.process(img_fnames, index_pairs)\n",
    "        timing.feature_detection += detect_and_match.time_detection\n",
    "        timing.feature_matching += detect_and_match.time_matching\n",
    "        time_detect_and_match = timing.feature_detection + timing.feature_matching \n",
    "        print(f'Features matched in  {time_detect_and_match:.4f} sec')\n",
    "        gc.collect()\n",
    "\n",
    "        # PREPARE COLMAP\n",
    "        database_path = f'{feature_dir}/colmap.db'\n",
    "        if dbg is not None:\n",
    "            dbg.database_path = database_path\n",
    "        if os.path.isfile(database_path):\n",
    "            os.remove(database_path)\n",
    "\n",
    "        fname_to_id = import_into_colmap(\n",
    "            img_dir, feature_dir=feature_dir, database_path=database_path)\n",
    "        output_path = f'{feature_dir}/colmap_rec_{opt.local_feature}'\n",
    "        if dbg is not None:\n",
    "            dbg.output_path = output_path\n",
    "            dbg.fname_to_id = fname_to_id\n",
    "        gc.collect()\n",
    "\n",
    "        # step3. GEOMETRIC VERIFICATION\n",
    "        t = time()\n",
    "        if opt.geometric_verification_alg == 'colmap':\n",
    "            pycolmap.match_exhaustive(database_path)\n",
    "        elif opt.geometric_verification_alg == 'magsac':\n",
    "            geometric_verification_magsac(database_path)\n",
    "        timing.geometric_verification += time() - t\n",
    "        print(f'Geometric Verification in  {timing.geometric_verification:.4f} sec')\n",
    "        gc.collect()\n",
    "\n",
    "        # step4. INCREMENTAL SFM\n",
    "        t=time()\n",
    "        mapper_options = pycolmap.IncrementalMapperOptions()\n",
    "        #mapper_options.multiple_models = False\n",
    "        mapper_options.min_model_size = 3\n",
    "        mapper_options.ba_refine_principal_point = True\n",
    "        mapper_options.extract_colors = False\n",
    "        mapper_options.num_threads = os.cpu_count()\n",
    "\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        reconstructions = pycolmap.incremental_mapping(\n",
    "            database_path=database_path, \n",
    "            image_path=img_dir, \n",
    "            output_path=output_path, \n",
    "            options=mapper_options)\n",
    "        print(reconstructions)\n",
    "        if not opt.debug:\n",
    "            clear_output(wait=False)\n",
    "        timing.reconstruction += time() - t\n",
    "        print(f'Reconstruction done in  {timing.reconstruction:.4f} sec')\n",
    "        gc.collect()\n",
    "\n",
    "        # step5. GATHER RESULTS\n",
    "        reconstructions = sorted(reconstructions.values(), key=lambda m: len(m.images))\n",
    "        for idx, rec in enumerate(reconstructions):\n",
    "            print(rec.summary())\n",
    "            for k, im in rec.images.items():\n",
    "                key1 = f'{dataset}/{scene}/images/{im.name}'\n",
    "                results[key1] = {}\n",
    "                results[key1][\"R\"] = im.rotmat()\n",
    "                results[key1][\"t\"] = im.tvec\n",
    "                \n",
    "\n",
    "        print(f'Registered: {dataset} / {scene} -> {len(results)} images')\n",
    "        print(f'Total: {dataset} / {scene} -> {len(img_fnames_ref)} images')\n",
    "        gc.collect()\n",
    "        result_queue.put([results, timing, dbg])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfdc1d-8ac6-488a-86ef-24c9d7912caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban / kyiv-puppet-theater -> 26 images\n",
      "heritage / dioscuri -> 174 images\n",
      "heritage / cyprus -> 30 images\n",
      "heritage / wall -> 43 images\n",
      "haiper / bike -> 15 images\n",
      "haiper / chairs -> 16 images\n",
      "haiper / fountain -> 23 images\n",
      "skipping kyiv-puppet-theater\n",
      "skipping dioscuri\n",
      "skipping cyprus\n",
      "skipping wall\n",
      "Got 15 images\n",
      "105, pairs to match, 0.0002 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:155: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_60 sm_70 sm_75 compute_70 compute_75.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "def process_all(data_dict):\n",
    "    gc.collect()\n",
    "    out_results = defaultdict(dict)\n",
    "    debugs = defaultdict(dict)\n",
    "    timings = defaultdict(dict)\n",
    "    \n",
    "    for dataset in data_dict.keys():\n",
    "        if dataset not in out_results:\n",
    "            out_results[dataset] = {}\n",
    "        for scene in data_dict[dataset]:\n",
    "            if opt.scenes_to_debug is not None and scene not in opt.scenes_to_debug:\n",
    "                print(f'skipping {scene}')\n",
    "                continue            \n",
    "            result_queue = mp.Queue()\n",
    "            p = mp.Process(target=process_scene, \n",
    "                           args=(data_dict, dataset, scene, result_queue))\n",
    "            p.start()\n",
    "            p.join()\n",
    "            if result_queue.empty():\n",
    "                print(f\"failed to process {scene}\")\n",
    "                continue\n",
    "            print(f'done processing {scene}')\n",
    "            results, timing, dbg = result_queue.get()\n",
    "            out_results[dataset][scene] = results\n",
    "            debugs[dataset][scene] = dbg\n",
    "            timings[dataset][scene] = timing\n",
    "                \n",
    "            create_submission(out_results, data_dict)\n",
    "            gc.collect()\n",
    "    pprint(timings)\n",
    "    return out_results, timings, debugs\n",
    "\n",
    "data_dict = read_submission_file()\n",
    "for dataset in data_dict:\n",
    "    for scene in data_dict[dataset]:\n",
    "        print(f'{dataset} / {scene} -> {len(data_dict[dataset][scene])} images')\n",
    "out_results, timings, debugs = process_all(data_dict)\n",
    "create_submission(out_results, data_dict)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dc258b5-0153-45aa-b25b-245882774116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric.\n",
    "\n",
    "@dataclass\n",
    "class Camera:\n",
    "    rotmat: np.array\n",
    "    tvec: np.array\n",
    "\n",
    "def quaternion_from_matrix(matrix):\n",
    "    M = np.array(matrix, dtype=np.float64, copy=False)[:4, :4]\n",
    "    m00 = M[0, 0]\n",
    "    m01 = M[0, 1]\n",
    "    m02 = M[0, 2]\n",
    "    m10 = M[1, 0]\n",
    "    m11 = M[1, 1]\n",
    "    m12 = M[1, 2]\n",
    "    m20 = M[2, 0]\n",
    "    m21 = M[2, 1]\n",
    "    m22 = M[2, 2]\n",
    "\n",
    "    # Symmetric matrix K.\n",
    "    K = np.array([[m00 - m11 - m22, 0.0, 0.0, 0.0],\n",
    "                  [m01 + m10, m11 - m00 - m22, 0.0, 0.0],\n",
    "                  [m02 + m20, m12 + m21, m22 - m00 - m11, 0.0],\n",
    "                  [m21 - m12, m02 - m20, m10 - m01, m00 + m11 + m22]])\n",
    "    K /= 3.0\n",
    "\n",
    "    # Quaternion is eigenvector of K that corresponds to largest eigenvalue.\n",
    "    w, V = np.linalg.eigh(K)\n",
    "    q = V[[3, 0, 1, 2], np.argmax(w)]\n",
    "\n",
    "    if q[0] < 0.0:\n",
    "        np.negative(q, q)\n",
    "    return q\n",
    "\n",
    "def evaluate_R_t(R_gt, t_gt, R, t, eps=1e-15):\n",
    "    t = t.flatten()\n",
    "    t_gt = t_gt.flatten()\n",
    "\n",
    "    q_gt = quaternion_from_matrix(R_gt)\n",
    "    q = quaternion_from_matrix(R)\n",
    "    q = q / (np.linalg.norm(q) + eps)\n",
    "    q_gt = q_gt / (np.linalg.norm(q_gt) + eps)\n",
    "    loss_q = np.maximum(eps, (1.0 - np.sum(q * q_gt)**2))\n",
    "    err_q = np.arccos(1 - 2 * loss_q)\n",
    "\n",
    "    GT_SCALE = np.linalg.norm(t_gt)\n",
    "    t = GT_SCALE * (t / (np.linalg.norm(t) + eps))\n",
    "    err_t = min(np.linalg.norm(t_gt - t), np.linalg.norm(t_gt + t))\n",
    "    \n",
    "    return np.degrees(err_q), err_t\n",
    "\n",
    "def compute_dR_dT(R1, T1, R2, T2):\n",
    "    '''Given absolute (R, T) pairs for two cameras, compute the relative pose difference, from the first.'''\n",
    "    \n",
    "    dR = np.dot(R2, R1.T)\n",
    "    dT = T2 - np.dot(dR, T1)\n",
    "    return dR, dT\n",
    "\n",
    "def compute_mAA(err_q, err_t, ths_q, ths_t):\n",
    "    '''Compute the mean average accuracy over a set of thresholds. Additionally returns the metric only over rotation and translation.'''\n",
    "\n",
    "    acc, acc_q, acc_t = [], [], []\n",
    "    for th_q, th_t in zip(ths_q, ths_t):\n",
    "        cur_acc_q = (err_q <= th_q)\n",
    "        cur_acc_t = (err_t <= th_t)\n",
    "        cur_acc = cur_acc_q & cur_acc_t\n",
    "        \n",
    "        acc.append(cur_acc.astype(np.float32).mean())\n",
    "        acc_q.append(cur_acc_q.astype(np.float32).mean())\n",
    "        acc_t.append(cur_acc_t.astype(np.float32).mean())\n",
    "    return np.array(acc), np.array(acc_q), np.array(acc_t)\n",
    "\n",
    "def dict_from_csv(csv_path, has_header):\n",
    "    old_format = csv_path.endswith('train_labels.csv')\n",
    "    csv_dict = {}\n",
    "    with open(csv_path, 'r') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if has_header and i == 0:\n",
    "                continue\n",
    "            if l:\n",
    "                if old_format:\n",
    "                    dataset, scene, image, R_str, T_str = l.strip().split(',')\n",
    "                else:\n",
    "                    image, dataset, scene, R_str, T_str = l.strip().split(',')\n",
    "                R = np.fromstring(R_str.strip(), sep=';').reshape(3, 3)\n",
    "                T = np.fromstring(T_str.strip(), sep=';')\n",
    "                if dataset not in csv_dict:\n",
    "                    csv_dict[dataset] = {}\n",
    "                if scene not in csv_dict[dataset]:\n",
    "                    csv_dict[dataset][scene] = {}\n",
    "                csv_dict[dataset][scene][image] = Camera(rotmat=R, tvec=T)\n",
    "    return csv_dict\n",
    "\n",
    "def eval_submission(submission_csv_path, ground_truth_csv_path, rotation_thresholds_degrees_dict, translation_thresholds_meters_dict, verbose=False):\n",
    "    '''Compute final metric given submission and ground truth files. Thresholds are specified per dataset.'''\n",
    "\n",
    "    submission_dict = dict_from_csv(submission_csv_path, has_header=True)\n",
    "    gt_dict = dict_from_csv(ground_truth_csv_path, has_header=True)\n",
    "\n",
    "    # Check that all necessary keys exist in the submission file\n",
    "    for dataset in gt_dict:\n",
    "        assert dataset in submission_dict, f'Unknown dataset: {dataset}'\n",
    "        for scene in gt_dict[dataset]:\n",
    "            assert scene in submission_dict[dataset], f'Unknown scene: {dataset}->{scene}'\n",
    "            for image in gt_dict[dataset][scene]:\n",
    "                assert image in submission_dict[dataset][scene], f'Unknown image: {dataset}->{scene}->{image}'\n",
    "\n",
    "    # Iterate over all the scenes\n",
    "    if verbose:\n",
    "        t = time()\n",
    "        print('*** METRICS ***')\n",
    "\n",
    "    metrics_per_dataset = []\n",
    "    for dataset in gt_dict:\n",
    "        metrics_per_scene = []\n",
    "        for scene in gt_dict[dataset]:\n",
    "            err_q_all = []\n",
    "            err_t_all = []\n",
    "            images = [camera for camera in gt_dict[dataset][scene]]\n",
    "            # Process all pairs in a scene\n",
    "            for i in range(len(images)):\n",
    "                for j in range(i + 1, len(images)):\n",
    "                    gt_i = gt_dict[dataset][scene][images[i]]\n",
    "                    gt_j = gt_dict[dataset][scene][images[j]]\n",
    "                    dR_gt, dT_gt = compute_dR_dT(gt_i.rotmat, gt_i.tvec, gt_j.rotmat, gt_j.tvec)\n",
    "\n",
    "                    pred_i = submission_dict[dataset][scene][images[i]]\n",
    "                    pred_j = submission_dict[dataset][scene][images[j]]\n",
    "                    dR_pred, dT_pred = compute_dR_dT(pred_i.rotmat, pred_i.tvec, pred_j.rotmat, pred_j.tvec)\n",
    "\n",
    "                    err_q, err_t = evaluate_R_t(dR_gt, dT_gt, dR_pred, dT_pred)\n",
    "                    err_q_all.append(err_q)\n",
    "                    err_t_all.append(err_t)\n",
    "\n",
    "            mAA, mAA_q, mAA_t = compute_mAA(err_q=err_q_all,\n",
    "                                            err_t=err_t_all,\n",
    "                                            ths_q=rotation_thresholds_degrees_dict[(dataset, scene)],\n",
    "                                            ths_t=translation_thresholds_meters_dict[(dataset, scene)])\n",
    "            if verbose:\n",
    "                print(f'{dataset} / {scene} ({len(images)} images, {len(err_q_all)} pairs) -> mAA={np.mean(mAA):.06f}, mAA_q={np.mean(mAA_q):.06f}, mAA_t={np.mean(mAA_t):.06f}')\n",
    "            metrics_per_scene.append(np.mean(mAA))\n",
    "\n",
    "        metrics_per_dataset.append(np.mean(metrics_per_scene))\n",
    "        if verbose:\n",
    "            print(f'{dataset} -> mAA={np.mean(metrics_per_scene):.06f}')\n",
    "            print()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Final metric -> mAA={np.mean(metrics_per_dataset):.06f} (t: {time() - t} sec.)')\n",
    "        print()\n",
    "\n",
    "    return np.mean(metrics_per_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60533b85-3ac0-41ff-a0a7-c8a6ef543b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** METRICS ***\n",
      "urban / kyiv-puppet-theater (26 images, 325 pairs) -> mAA=0.000000, mAA_q=0.010154, mAA_t=0.036615\n",
      "urban -> mAA=0.000000\n",
      "\n",
      "heritage / dioscuri (174 images, 15051 pairs) -> mAA=0.001787, mAA_q=0.003535, mAA_t=0.014006\n",
      "heritage / cyprus (30 images, 435 pairs) -> mAA=0.000000, mAA_q=0.000460, mAA_t=0.003218\n",
      "heritage / wall (43 images, 903 pairs) -> mAA=0.000111, mAA_q=0.682281, mAA_t=0.000111\n",
      "heritage -> mAA=0.000633\n",
      "\n",
      "haiper / bike (15 images, 105 pairs) -> mAA=0.000000, mAA_q=0.000000, mAA_t=0.000000\n",
      "haiper / chairs (16 images, 120 pairs) -> mAA=0.000000, mAA_q=0.000000, mAA_t=0.000000\n",
      "haiper / fountain (23 images, 253 pairs) -> mAA=0.000000, mAA_q=0.000000, mAA_t=0.000000\n",
      "haiper -> mAA=0.000000\n",
      "\n",
      "Final metric -> mAA=0.000211 (t: 1.8400566577911377 sec.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if opt.test_or_train == 'train':\n",
    "    # Set rotation thresholds per scene.\n",
    "    rotation_thresholds_degrees_dict = {\n",
    "        **{('haiper', scene): np.linspace(1, 10, 10) for scene in ['bike', 'chairs', 'fountain']},\n",
    "        **{('heritage', scene): np.linspace(1, 10, 10) for scene in ['cyprus', 'dioscuri']},\n",
    "        **{('heritage', 'wall'): np.linspace(0.2, 10, 10)},\n",
    "        **{('urban', 'kyiv-puppet-theater'): np.linspace(1, 10, 10)},\n",
    "    }\n",
    "\n",
    "    translation_thresholds_meters_dict = {\n",
    "        **{('haiper', scene): np.geomspace(0.05, 0.5, 10) for scene in ['bike', 'chairs', 'fountain']},\n",
    "        **{('heritage', scene): np.geomspace(0.1, 2, 10) for scene in ['cyprus', 'dioscuri']},\n",
    "        **{('heritage', 'wall'): np.geomspace(0.05, 1, 10)},\n",
    "        **{('urban', 'kyiv-puppet-theater'): np.geomspace(0.5, 5, 10)},\n",
    "    }\n",
    "\n",
    "    eval_submission(submission_csv_path='submission.csv',\n",
    "                    ground_truth_csv_path=opt.input_filepath,\n",
    "                    rotation_thresholds_degrees_dict=rotation_thresholds_degrees_dict,\n",
    "                    translation_thresholds_meters_dict=translation_thresholds_meters_dict,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6f9337b-3716-4742-a601-fcce6194feb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_116/2468381653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mvisualize_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_116/3913567185.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_or_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_long_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_required\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_116/2468381653.py\u001b[0m in \u001b[0;36mvisualize_all\u001b[0;34m(data_dict, out_results, debugs)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes_to_debug\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes_to_debug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bike'"
     ]
    }
   ],
   "source": [
    "@train_only\n",
    "def visualize_all(data_dict, out_results, debugs):\n",
    "    for dataset, scene_dict in data_dict.items():\n",
    "        for scene in scene_dict.keys():\n",
    "            if opt.scenes_to_debug is not None and scene not in opt.scenes_to_debug:\n",
    "                continue\n",
    "            visualize(data_dict, out_results, dataset, scene, debugs[dataset][scene])\n",
    "            \n",
    "def get_points(recon):\n",
    "    pts = np.stack([p.xyz for p in recon.points3D.values()], axis=-1)\n",
    "    return pts\n",
    "\n",
    "def get_viewpoints(recon):\n",
    "    viewpoints = []\n",
    "    for img in recon.images.values():\n",
    "        viewpoints.append((img.name, img.rotmat(), img.tvec))\n",
    "    viewpoints.sort()\n",
    "    imgs = [v[0] for v in viewpoints]\n",
    "    rots = np.stack([v[1] for v in viewpoints], axis=-1)\n",
    "    trans = np.stack([v[2] for v in viewpoints], axis=-1)\n",
    "    return imgs, rots, trans\n",
    "    \n",
    "\n",
    "def plot_points(vis_objs, points, color='black', size=1):\n",
    "    import plotly.graph_objects as go\n",
    "    vis_objs.append(go.Scatter3d(\n",
    "        x=points[0],\n",
    "        y=points[1],\n",
    "        z=points[2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "            size=size,\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "def plot_cams(vis_objs, rots, trans, color='black'):\n",
    "    import plotly.graph_objects as go\n",
    "    axis_colors = ['red', 'green', 'blue']\n",
    "    for axis, axis_color in enumerate(axis_colors):\n",
    "        points = np.concatenate([trans, \n",
    "                                 trans + rots[:, axis, :] * 2, \n",
    "                                 np.full_like(trans, np.nan)])\n",
    "        points = points.T.reshape(-1, 3).T\n",
    "        vis_objs.append(go.Scatter3d(\n",
    "            x=points[0],\n",
    "            y=points[1],\n",
    "            z=points[2],\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=axis_color,\n",
    "                width=3,\n",
    "            )\n",
    "        ))\n",
    "    plot_points(vis_objs, trans, color=color, size=2)\n",
    "    \n",
    "def align_recon(rec, gt_rec):\n",
    "    common_fnames = []\n",
    "    gt_positions = []\n",
    "    for img in rec.images.values():\n",
    "        for gt_img in gt_rec.images.values():\n",
    "            if img.name == gt_img.name:\n",
    "                common_fnames.append(img.name)\n",
    "                gt_positions.append(gt_img.projection_center().reshape(3, 1))\n",
    "                break\n",
    "    transform = rec.align_robust(common_fnames, gt_positions, 5)\n",
    "    print(align_recon, transform)\n",
    "    return transform\n",
    "\n",
    "def load_reconstructions(output_path):\n",
    "    recon_fnames = sorted(glob(f'{output_path}/*'))\n",
    "    reconstructions = []\n",
    "    for recon_fname in recon_fnames:\n",
    "        reconstructions.append(pycolmap.Reconstruction(recon_fname))\n",
    "    reconstructions.sort(key=lambda m: len(m.images))\n",
    "    return reconstructions\n",
    "            \n",
    "def visualize(data_dict, out_results, dataset, scene, dbg):\n",
    "    print(dbg)\n",
    "\n",
    "    src = f'/kaggle/input/image-matching-challenge-2023/train/{dataset}/{scene}'\n",
    "    gt_rec = pycolmap.Reconstruction(f'{src}/sfm')\n",
    "    fig = viz_3d.init_figure()\n",
    "    viz_3d.plot_reconstruction(fig, gt_rec, points=False, color='rgba(0,100,0,0.1)', name=\"GT Reconstruction\", cs=5)\n",
    "    if dbg is not None:\n",
    "        reconstructions = load_reconstructions(dbg.output_path)\n",
    "        rec = reconstructions[-1]\n",
    "        print(rec)\n",
    "        align_recon(rec, gt_rec)\n",
    "        viz_3d.plot_reconstruction(fig, rec, color='rgba(0,255,255,0.5)', name=\"Reconstruction\", cs=5)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "visualize_all(data_dict, out_results, debugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7adb-a92a-4056-8bcb-37fe67b97458",
   "metadata": {},
   "outputs": [],
   "source": [
    "@train_only\n",
    "def debug_all(debugs):\n",
    "    for dataset in debugs.keys():\n",
    "        for scene, dbg in debugs[dataset].items():\n",
    "            print(f'{dataset}[{scene}]')\n",
    "            dbg = debugs[dataset][scene]\n",
    "            if dbg is not None:\n",
    "                debug(dbg, dataset, scene)\n",
    "\n",
    "def debug_feature_matches(db, img_dirname):\n",
    "    count = 0\n",
    "    ordered_index_pairs = []\n",
    "    for idx1, idx2, _ in db.get_all_matches():\n",
    "        try:\n",
    "            verified_matches, F, match_config = db.get_two_view_geometry(idx1, idx2)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        ordered_index_pairs.append((len(verified_matches), idx1, idx2))\n",
    "    ordered_index_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "    print(ordered_index_pairs)\n",
    "\n",
    "    for _, idx1, idx2 in ordered_index_pairs[::10]:\n",
    "        kp1 = db.get_keypoints(idx1)\n",
    "        kp2 = db.get_keypoints(idx2)\n",
    "        _, img1, *_ = db.get_image(idx1)\n",
    "        _, img2, *_ = db.get_image(idx2)\n",
    "        img1 = cv2.imread(os.path.join(img_dirname, img1))\n",
    "        img2 = cv2.imread(os.path.join(img_dirname, img2))\n",
    "        print(idx1, idx2)\n",
    "        \n",
    "        pair_id = image_ids_to_pair_id(idx1, idx2)\n",
    "        matches = db.get_matches(idx1, idx2)\n",
    "        verified_matches, F, match_config = db.get_two_view_geometry(idx1, idx2)\n",
    "\n",
    "        print('verified.shape', verified_matches.shape)\n",
    "        draw_matches(img1, kp1, img2, kp2, matches, mask=None)\n",
    "        draw_matches(img1, kp1, img2, kp2, verified_matches, mask=None)\n",
    "\n",
    "def show_imgs(img_fnames, cols=3):\n",
    "    for i in range(0, len(img_fnames), cols):\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        plt.tight_layout()\n",
    "        for j in range(cols):\n",
    "            if i + j < len(img_fnames):\n",
    "                plt.subplot(1, cols, j + 1)\n",
    "                plt.imshow(Image.open(img_fnames[i + j]))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "def debug_unaligned(dbg):\n",
    "    recon = load_reconstructions(dbg.output_path)[-1]\n",
    "    image_fnames = dbg.img_fnames\n",
    "    \n",
    "    aligned = set(img.name for img_id, img in recon.images.items())\n",
    "    unaligned = [i for i in image_fnames if os.path.basename(i) not in aligned]\n",
    "    show_imgs(unaligned)\n",
    "    \n",
    "def count_overlap(recon1, recon2):\n",
    "    return recon1.find_common_reg_image_ids(recon2)\n",
    "    #imgs1 = set(img.name for img_id, img in recon1.images.items())\n",
    "    #imgs2 = set(img.name for img_id, img in recon2.images.items())\n",
    "    #return len(imgs1 & imgs2)\n",
    "\n",
    "def debug_recon_overlap(dbg):\n",
    "    reconstructions = load_reconstructions(dbg.output_path)\n",
    "    img_groups = []\n",
    "    for recon in reconstructions:\n",
    "        img_groups.append(set(img.name for img_id, img in recon.images.items()))\n",
    "        \n",
    "    for g1 in range(len(img_groups)):\n",
    "        for g2 in range(len(img_groups)):\n",
    "            if g1 == g2:\n",
    "                continue\n",
    "            print(g1, g2, img_groups[g1] & img_groups[g2])\n",
    "        \n",
    "def test_merge(dbg):\n",
    "    reconstructions = load_reconstructions(dbg.output_path)\n",
    "    while reconstructions:\n",
    "        recon1 = reconstructions.pop()\n",
    "        if not reconstructions:\n",
    "            break\n",
    "        reconstructions.sort(key=lambda r: count_overlap(recon1, r), reverse=True)\n",
    "        for idx2, recon2 in enumerate(reconstructions):\n",
    "            if recon1.merge(recon2, 1000.0):\n",
    "                break\n",
    "            else:\n",
    "                print('fail!')\n",
    "        else:\n",
    "            break\n",
    "        reconstructions.pop(idx2)\n",
    "    print(len(recon1.images))\n",
    "    \n",
    "    \n",
    "\n",
    "def debug(dbg, dataset, scene):\n",
    "    db = COLMAPDatabase(dbg.database_path)\n",
    "    #test_merge(dbg)\n",
    "    debug_feature_matches(db, dbg.img_dirname)\n",
    "    #debug_unaligned(dbg)\n",
    "    #debug_recon_overlap(dbg)\n",
    "\n",
    "    \n",
    "debug_all(debugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad059422-78bc-434a-a625-90679c5f3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 'submission.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95496a8f-42ce-4213-bbe4-46fb2c9c7daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
